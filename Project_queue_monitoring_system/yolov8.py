# -*- coding: utf-8 -*-
"""Yolov8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mpktUVIN7jCffDBZAo_7Dvo9HPDyUy9o
"""

from google.colab import drive
drive.mount('/content/drive')

from ultralytics import YOLO

# Load a model
# model = YOLO("yolov8n.yaml")  # build a new model from scratch
model = YOLO("yolov8n.pt")  # load a pretrained model (recommended for training)

# Use the model
model.train(data="coco128.yaml", epochs=3)  # train the model
metrics = model.val()  # evaluate model performance on the validation set
results = model("https://ultralytics.com/images/bus.jpg")  # predict on an image
path = model.export(format="onnx")  # export the model to ONNX format

from ultralytics import YOLO

# Load a model
model = YOLO("yolov8n.pt")  # build a new model from scratch

# Use the model
results = model.train(data="yolo.yaml", epochs=1)  # train the model

from ultralytics import YOLO

results = model.val(data="yolo.yaml")

pip install netron

# ONNX 可视化
import netron
netron.start('/Users/duhaoxun/Desktop/Project/runs/detect/train28/weights/best.onnx')

import subprocess

def check_gpu_availability():
    try:
        # Run the nvidia-smi command and capture the output
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)

        # Check if the command executed successfully
        if result.returncode == 0:
            print("GPU is available.")
            print("GPU Information:")
            print(result.stdout)
        else:
            print("No NVIDIA GPU detected.")
    except FileNotFoundError:
        print("nvidia-smi command not found. Make sure NVIDIA GPU drivers are installed.")

# Call the function to check GPU availability
check_gpu_availability()

!pip install ultralytics

# !pip install torch torchvision
# !pip install opencv-python
# !pip install matplotlib  # For plotting the images, if necessary

# !git clone https://github.com/ultralytics/yolov5
# !cd yolov5
# !pip install -r requirements.txt

import torch
from PIL import Image
import numpy as np

# Load model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # 'yolov5s' is the smallest model

def detect_people(image_path):
    # Load image
    img = Image.open(image_path)

    # Inference
    results = model(img)

    # Results
    results.print()  # Print results to console

    # Extract detection data
    detections = results.xyxy[0]  # Bounding boxes, confidences, and class IDs

    # Filter for persons (class ID 0 in COCO)
    person_detections = detections[detections[:, 5] == 0]
    num_people = len(person_detections)

    print(f"Number of people detected: {num_people}")
    return num_people

# Example usage
if __name__ == "__main__":
    image_path = '1.jpg'
    detect_people(image_path)

# Video Detect
from ultralytics import YOLO
import cv2

model = YOLO('yolov8n.pt')

video_path = "/Users/duhaoxun/Desktop/Project/video.mp4"
cap = cv2.VideoCapture(video_path)

ret = True
while ret:
    ret,frame = cap.read()

    results = model.track(frame, persist=True)

    frame_ = results[0].plot()

    cv2.imshow('frame',frame_)

    if cv2.waitKey(25) & 0xFF == ord('q'):
        break

