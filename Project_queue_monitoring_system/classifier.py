# -*- coding: utf-8 -*-
"""Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pDqWvUBslMv_voSAn9xnAd_em2O3bssC
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# !pip install nbimporter
import os
import importlib
# Import code from other_notebook.ipynb
os.chdir('/content/drive/MyDrive/Colab Notebooks/Project/')
# %run VGG_net.ipynb
# from Classifier import VGGFeature

"""# Define the sample class"""

import os
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import torchvision.transforms as transforms

norm_mean = [0.485, 0.456, 0.406]
norm_std = [0.229, 0.224, 0.225]

inference_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.ToTensor(),
    transforms.Normalize(norm_mean, norm_std),
])

def img_transform(img_rgb, transform=None):
    """
    transform images
    :param img_rgb: PIL Image
    :param transform: torchvision.transform
    :return: tensor
    """

    if transform is None:
        raise ValueError("there is no transform")

    img_t = transform(Image.fromarray(img_rgb))
    return img_t

class Sample:
    def __init__(self, idx=0, fname='', img=None, feat=None, label=None):
        self.idx = idx
        self.fname = fname
        self.img = img
        self.torch_img=img
        self.vgg_feat = feat
        self.label = label
        self.pred = None
# # fig, ax = plt.subplots()
samples=[]
labels={0:'not_queue',1:'queuing',2:'serving'}
cat={'not_queue':0, 'queuing':1, 'serving':2}



"""# Corrupt bounding box bounding boxes"""

import os
import cv2
from pycocotools.coco import COCO
from google.colab.patches import cv2_imshow
annotate=None
samples=[]
def crop_images_with_coco_annotations(image_folder, annotation_file, output_folder):
    # Load COCO annotations
    coco = COCO(annotation_file)
    image_ids = coco.getImgIds()
    # Create output folders for each bounding box type
    os.makedirs(output_folder, exist_ok=True)
    bbox_types = ['not_queue', 'queuing', 'serving']
    for bbox_type in bbox_types:
        bbox_output_folder = os.path.join(output_folder, bbox_type)
        os.makedirs(bbox_output_folder, exist_ok=True)
    id_num=0
    # Process each image
    for image_file in image_ids:
        # Load the image
        coco_img = coco.loadImgs(image_ids[image_file])[0]['file_name']
        image_path = os.path.join(image_folder, coco_img)
        image = cv2.imread(image_path)
        # cv2_imshow(image)
        print(coco_img)
        # Get image ID from the file name
        # image_id = os.path.splitext(image_file)
        print(image_file)

        # Get annotation IDs for the image
        annotation_ids = coco.getAnnIds(imgIds=[image_file])

        # Load annotations for the image
        annotations = coco.loadAnns(annotation_ids)
        print(annotations)
        # Crop the image using the bounding box annotations
        for i, annotation in enumerate(annotations):
            bbox_type = annotation['category_id']
            x, y, width, height = annotation['bbox']
            x1, y1, x2, y2 = int(x), int(y), int(x + width), int(y + height)
            cropped_image = image[y1:y2, x1:x2]

            # Save the cropped image to the corresponding output folder
            bbox_output_folder = os.path.join(output_folder, bbox_types[bbox_type-1])
            output_path = os.path.join(bbox_output_folder, f"cropped_image_{id_num}.jpg")
            id_num+=1
            # display(cropped_image)
            samples.append(Sample(img=img_transform(cv2.resize(cropped_image,(200,300)), inference_transform),label=cat[bbox_types[bbox_type-1]]))
            cv2.imwrite(output_path, cropped_image)

    print("Images cropped and saved successfully.")

if __name__ == "__main__":
    image_folder = "/content/drive/MyDrive/Colab Notebooks/Project/Queue counting and detection.v10i.coco/train"
    annotation_file = "/content/drive/MyDrive/Colab Notebooks/Project/Queue counting and detection.v10i.coco/train/_annotations.coco.json"
    output_folder = "/content/drive/MyDrive/Colab Notebooks/Project/Splited_image/"
    crop_images_with_coco_annotations(image_folder, annotation_file, output_folder)

import os
import cv2
from pycocotools.coco import COCO
from google.colab.patches import cv2_imshow
annotate=None
valid=[]
def crop_images_with_coco_annotations(image_folder, annotation_file, output_folder):
    # Load COCO annotations
    coco = COCO(annotation_file)
    image_ids = coco.getImgIds()
    # Create output folders for each bounding box type
    os.makedirs(output_folder, exist_ok=True)
    bbox_types = ['not_queue', 'queuing', 'serving']
    for bbox_type in bbox_types:
        bbox_output_folder = os.path.join(output_folder, bbox_type)
        os.makedirs(bbox_output_folder, exist_ok=True)
    id_num=0
    # Process each image
    for image_file in image_ids:
        # Load the image
        coco_img = coco.loadImgs(image_ids[image_file])[0]['file_name']
        image_path = os.path.join(image_folder, coco_img)
        image = cv2.imread(image_path)
        # cv2_imshow(image)
        print(coco_img)
        # Get image ID from the file name
        # image_id = os.path.splitext(image_file)
        print(image_file)

        # Get annotation IDs for the image
        annotation_ids = coco.getAnnIds(imgIds=[image_file])

        # Load annotations for the image
        annotations = coco.loadAnns(annotation_ids)
        print(annotations)
        # Crop the image using the bounding box annotations
        for i, annotation in enumerate(annotations):
            bbox_type = annotation['category_id']
            x, y, width, height = annotation['bbox']
            x1, y1, x2, y2 = int(x), int(y), int(x + width), int(y + height)
            cropped_image = image[y1:y2, x1:x2]

            # Save the cropped image to the corresponding output folder
            bbox_output_folder = os.path.join(output_folder, bbox_types[bbox_type-1])
            output_path = os.path.join(bbox_output_folder, f"cropped_image_{id_num}.jpg")
            id_num+=1
            # display(cropped_image)
            valid.append(Sample(img=img_transform(cv2.resize(cropped_image,(200,300)), inference_transform),label=cat[bbox_types[bbox_type-1]]))
            cv2.imwrite(output_path, cropped_image)

    print("Images cropped and saved successfully.")

if __name__ == "__main__":
    image_folder = "/content/drive/MyDrive/Colab Notebooks/Project/Queue counting and detection.v10i.coco/valid"
    annotation_file = "/content/drive/MyDrive/Colab Notebooks/Project/Queue counting and detection.v10i.coco/valid/_annotations.coco.json"
    output_folder = "/content/drive/MyDrive/Colab Notebooks/Project/Valid_Split_image/"
    crop_images_with_coco_annotations(image_folder, annotation_file, output_folder)

from sklearn.model_selection import train_test_split
train, validation = train_test_split(samples, test_size=0.2, random_state=42)
validation=valid
# train=samples
train_feats = [sample.torch_img.numpy() for sample in train]
train_labels = [sample.label for sample in train]
validation_feats = [sample.torch_img.numpy() for sample in validation]
validation_labels = [sample.label for sample in validation]
num_cats=3
temp_cats = [[0] * num_cats for _ in range(len(train_labels))]
for i in range(len(train_labels)):
  temp_cats[i][train_labels[i]]=1
train_cats=temp_cats
temp_cats = [[0] * num_cats for _ in range(len(validation_labels))]
for i in range(len(validation_labels)):
  temp_cats[i][validation_labels[i]]=1
val_cats=temp_cats

import torch.nn as nn
import torch
import torch.nn.functional as F
from torchvision import models as models
from torch.autograd import Variable
train_feats = torch.tensor(train_feats).to(torch.float32)
train_x = torch.reshape(train_feats,[train_feats.shape[0],3,384,256])
val_feats = torch.tensor(validation_feats).to(torch.float32)
val_x = torch.reshape(val_feats,[val_feats.shape[0],3,384,256])
train_y = torch.tensor(train_cats).to(torch.float32)
val_y = torch.tensor(val_cats).to(torch.float32)

force_cpu = False

if torch.cuda.is_available() and not force_cpu:
    device = torch.device('cuda:0')
else:
    device = torch.device('cpu')

print('We are using device', device)

VGG = VGGFeature().to(device)
criterion = nn.CrossEntropyLoss()

# create optimizer. 1st parameter: the parameters will be optimized; 2nd: learning rate
optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, VGG.parameters()), lr=0.05)
train_conv=[]
batch_size = 30
num_batches = len(train_feats) // batch_size
num_epochs=50
train_loss_values = []
val_loss_values = []
best_loss=100
# Define the training loop
counter=0
for epoch in range(num_epochs):
    print(f"Epoch {epoch+1}/{num_epochs}")
    running_train_loss = 0.0
    for batch_idx in range(num_batches):
        torch.cuda.empty_cache()
        start_idx = batch_idx * batch_size
        end_idx = (batch_idx + 1) * batch_size

        if torch.cuda.is_available():
            inputs = Variable(train_x[start_idx:end_idx]).cuda()
            target = Variable(train_y[start_idx:end_idx]).cuda()
        else:
            inputs = Variable(train_x[start_idx:end_idx])
            target = Variable(train_y[start_idx:end_idx])
                # Clear gradients
        optimizer.zero_grad()
        # Forward pass
        out,_= VGG(inputs)
        # Calculate loss
        loss = criterion(out, target)

        # Backward propagation
        loss.backward()
        # Updating parameters via SGD
        optimizer.step()
        # Print training progress
        if(batch_idx==num_batches-1):
          print(f"Batch {batch_idx+1}/{num_batches} - Loss: {loss.item()}")
        running_train_loss += loss.item()
    epoch_train_loss = running_train_loss / train_x.shape[0]
    train_loss_values.append(epoch_train_loss)
    # Validation phase
    VGG.eval()
    running_val_loss = 0.0
    with torch.no_grad():
        val_outputs,_ = VGG(val_x.cuda())
        val_loss = criterion(val_outputs, val_y.cuda())
        running_val_loss += val_loss.item()
    len_val=15
    # # Calculate average validation loss for the epoch
    epoch_val_loss = running_val_loss / len_val
    val_loss_values.append(epoch_val_loss)
    if(running_val_loss<best_loss):
        best_loss=running_val_loss
        best_model=VGG
        counter=0
    else:
        counter+=1
    if(counter>5):
        break
    # Print the loss for the epoch
    print(f"Epoch {epoch+1} - Training Loss: {epoch_train_loss}, Validation Loss: {epoch_val_loss}")

# Plot the loss values for training and validation sets on the same chart
plt.plot(train_loss_values, marker='o', label='Training Loss')
plt.plot(val_loss_values, marker='o', label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss during Training and Validation')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import accuracy_score
best_model=vgg_model.cpu()
# best_model=best_model.cpu()
for param in best_model.parameters():
    param.requires_grad = False
train_out,train_conv = best_model(train_x.requires_grad_(False))
train_conv=train_conv.detach()
val_out,val_conv = best_model(val_x.requires_grad_(False))
val_conv=val_conv.detach()

train_x.shape

max_values = np.argmax(val_out.detach().cpu().numpy(), axis=1)

max_values

accuracy = accuracy_score(val_label, max_values)
accuracy

train_conv=train_conv.detach().cpu()
ind=0
for conv in train_conv.numpy():
  train[ind].vgg_feat=conv
  ind+=1
val_conv=val_conv.detach().cpu()
ind=0
for conv in val_conv.numpy():
  validation[ind].vgg_feat=conv
  ind+=1

from sklearn import svm
from sklearn.metrics import accuracy_score
train_feat=[sample.vgg_feat for sample in train]
train_label=[sample.label for sample in train]
val_feat=[sample.vgg_feat for sample in validation]
val_label=[sample.label for sample in validation]
from sklearn.neighbors import KNeighborsClassifier
# 3. Model Training
from sklearn.ensemble import RandomForestClassifier
# svm_classifier = svm.SVC(kernel='linear')
# svm_classifier = RandomForestClassifier()
svm_classifier = KNeighborsClassifier()
svm_classifier.fit(train_conv, train_label)

# 4. Model Evaluation
y_pred = svm_classifier.predict(val_feat)
accuracy = accuracy_score(val_label, y_pred)
print("Accuracy:", accuracy)

# # 5. Prediction
# # Assuming you have a new, unseen image represented by its features stored in a variable called 'new_image_features'
predicted_class = svm_classifier.predict(val_feat)
print("Predicted Class:", predicted_class)
print("True class",val_label)

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
# Define the SVM classifier
svm_clf = svm.SVC()

# Define the RFC classifier
rfc = RandomForestClassifier()

# Define the parameter grid to search
param_grid = {
    'n_estimators': [100, 200, 300],  # Number of trees in the forest
    'max_depth': [None, 5, 10],  # Maximum depth of each tree
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node
    'max_features': ['auto', 'sqrt'],  # Number of features to consider when looking for the best split
    'random_state': [42]
}

# Perform grid search
grid_search = GridSearchCV(rfc, param_grid, cv=5)
grid_search.fit(train_conv,train_label)

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)

# Evaluate the best model on the test set
best_svm_clf = grid_search.best_estimator_
y_pred = best_svm_clf.predict(val_conv)
accuracy = accuracy_score(val_label, y_pred)
print("Accuracy:", accuracy)

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.datasets import make_classification
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score

# Generate a sample dataset
X, y = make_classification(n_samples=1000, n_features=10, random_state=42)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the first-level models
estimators = [
    ('dt', DecisionTreeClassifier()),
    ('knn', KNeighborsClassifier()),
    ('rf', RandomForestClassifier()),
    ('gnb', GaussianNB())
]

# Define the second-level model (meta-classifier)
meta_classifier = RandomForestClassifier()

# Build the stacking classifier
stacking_clf = StackingClassifier(estimators=estimators, final_estimator=meta_classifier)

# Define the parameter grid to search
param_grid = {
    'dt__max_depth': [None, 2, 4],
    'knn__n_neighbors': [3, 5, 7],
    'rf__n_estimators': [50, 100, 200],
    'rf__max_depth': [None, 2, 4],
    'meta_classifier__n_estimators': [50, 100, 200],
    'meta_classifier__max_depth': [None, 2, 4]
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(stacking_clf, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)

# Evaluate the stacking classifier with the best parameters on the test set
best_stacking_clf = grid_search.best_estimator_
y_pred = best_stacking_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.datasets import make_classification
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import accuracy_score

# Define the first-level models
estimators = [
    ('dt', DecisionTreeClassifier()),
    ('knn', KNeighborsClassifier()),
    ('rf', RandomForestClassifier()),
    ('gnb', GaussianNB())
]

# Define the second-level model (meta-classifier)
meta_classifier = RandomForestClassifier()

# Build the stacking classifier
stacking_clf = StackingClassifier(estimators=estimators, final_estimator=meta_classifier)

# Define the parameter grid to search
param_grid = {
    'final_estimator__n_estimators': [50, 100, 200],
    'cv': [3, 5, 10],
    'n_jobs': [1, -1],
    'passthrough': [True, False],
    'stack_method': ['auto', 'predict_proba', 'decision_function'],
    'verbose': [0, 1, 2]
}
# Perform grid search with cross-validation
grid_search = GridSearchCV(stacking_clf, param_grid, cv=5, scoring='accuracy')
grid_search.fit(train_conv, train_label)

# Get the best parameters and best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)

# Evaluate the stacking classifier with the best parameters on the test set
best_stacking_clf = grid_search.best_estimator_
y_pred = best_stacking_clf.predict(val_conv)
accuracy = accuracy_score(val_label, y_pred)
print("Accuracy:", accuracy)

vgg_model=vgg_model
out,train_conv=vgg_model(train_x.cuda())

# # # Create an instance of the neural network model
import joblib
# # from sklearn import svm
# # # ... Training code for the SVM model ...
svm_model_path = "/content/drive/MyDrive/Colab Notebooks/Project/output_model/3_class_SVM_model.pkl"
joblib.dump(svm_classifier, svm_model_path)

# vgg_path = ""
# Create an instance of the model
# Save the model
# model_path = "/content/drive/MyDrive/Colab Notebooks/Project/output_model/3_class_vgg_extractor.pt"
# torch.save(best_model, model_path)

best_model

# Load the pretrained model state dictionary
import torch
pretrained_model_path = "/content/drive/MyDrive/Colab Notebooks/Project/output_model/3_class_vgg_extractor.pt"
vgg_model = torch.load(pretrained_model_path,map_location=torch.device("cpu"))

vgg_model=vgg_model.cpu()
out,val_conv=vgg_model(val_x)

# train_conv=train_conv.detach().cpu()
ind=0
# for conv in train_conv.numpy():
#   train[ind].vgg_feat=conv
#   ind+=1
val_conv=val_conv.detach().cpu()
ind=0
for conv in val_conv.numpy():
  validation[ind].vgg_feat=conv
  ind+=1

val_feat=[sample.vgg_feat for sample in validation]

from sklearn import svm
import joblib
from sklearn.metrics import accuracy_score
val_label=[sample.label for sample in validation]
# Load the pretrained SVM model
pretrained_model_path = "/content/drive/MyDrive/Colab Notebooks/Project/output_model/svm_model.pkl"
svm_model = joblib.load(pretrained_model_path)

# Make predictions using the loaded model
predictions = svm_model.predict(val_conv)

# Print the predictions
print(predictions)
accuracy = accuracy_score(val_label, predictions)
print("Accuracy:", accuracy)