{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fR9AHA26_CCG",
    "outputId": "451c75b0-e056-4ee9-dd12-e9d114feb41c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# try:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive')\n",
    "#     workspace = '/content/drive/MyDrive'\n",
    "# except:\n",
    "#     workspace = '.'\n",
    "!pip install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0\n",
    "%pip install -U opencv-python\n",
    "%pip install -U opencv-contrib-python\n",
    "# %pip install -U grad-cam\n",
    "%pip install eniops\n",
    "%pip install vit-pytorch\n",
    "%pip install -U grad-cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWe7ktXSSrCj"
   },
   "source": [
    "#Read and load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "eQZdleQg_XmX",
    "outputId": "d24ada69-3713-4945-fbee-f53a019cfe45"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "labels={\"real\":0,\"cyberpunk\":1,\"cartoon\":2,\"No-style\":3}\n",
    "category={0:\"real\",1:\"cyberpunk\",2:\"cartoon\",3:\"No-style\"}\n",
    "# Path to the folder containing the images\n",
    "folder_path = 'Real_images/Real_images'\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "def img_transform(img_rgb, transform=None):\n",
    "    \"\"\"\n",
    "    transform images\n",
    "    :param img_rgb: PIL Image\n",
    "    :param transform: torchvision.transform\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "\n",
    "    if transform is None:\n",
    "        raise ValueError(\"there is no transform\")\n",
    "\n",
    "    img_t = transform(Image.fromarray(img_rgb))\n",
    "    return img_t\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self, idx=0, fname='', img=None, feat=None, label=None):\n",
    "        self.idx = idx\n",
    "        self.fname = fname\n",
    "        self.img = img\n",
    "        self.torch_img=img\n",
    "        self.vgg_feat = feat\n",
    "        self.label = label\n",
    "        self.patches = None\n",
    "        self.pred_set = []\n",
    "        self.si_score = []\n",
    "        self.pred = None\n",
    "# fig, ax = plt.subplots()\n",
    "samples=[]\n",
    "image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(len(image_files))\n",
    "for i, file in enumerate(image_files):\n",
    "  image_path = os.path.join(folder_path, file)\n",
    "  img = cv2.imread(image_path, cv2.IMREAD_COLOR)[..., ::-1]\n",
    "  if i == 0:\n",
    "    H, W, C = img.shape\n",
    "  else:\n",
    "    img = cv2.resize(img, (W, H))\n",
    "    # plt.title(file)\n",
    "    # plt.imshow(img)\n",
    "  samples.append(Sample(img=img,label=0))\n",
    "print(len(samples))\n",
    "folder_path = 'Real_images/Indoor'\n",
    "image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "for i, file in enumerate(image_files):\n",
    "  image_path = os.path.join(folder_path, file)\n",
    "  img = cv2.imread(image_path, cv2.IMREAD_COLOR)[..., ::-1]\n",
    "  img = cv2.resize(img, (W, H))\n",
    "    # plt.title(file)\n",
    "    # plt.imshow(img)\n",
    "  samples.append(Sample(img=img,label=0))\n",
    "print(len(samples))\n",
    "\n",
    "folder_path='AI_generated_images/AI_generated_images'\n",
    "folder_paths = ['/cyberpunk', '/Cartoon', '/No_style']\n",
    "for i in range(3):\n",
    "  folder_paths[i]=folder_path+folder_paths[i]\n",
    "# Iterate over the folder paths\n",
    "for i, folder_path in enumerate(folder_paths):\n",
    "    # Get a list of all image files in the folder\n",
    "  image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "  for j, file in enumerate(image_files):\n",
    "    image_path=os.path.join(folder_path,file)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)[..., ::-1]\n",
    "    img = cv2.resize(img, (W, H))\n",
    "    # plt.imshow(img)\n",
    "    samples.append(Sample(img=img,label=i+1))\n",
    "  print(np.array(samples).shape)\n",
    "# Adjust the spacing between subplots\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWyi6a3NLSsn"
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "  sample.torch_img=img_transform(sample.img, inference_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUVtCjb39Iyx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(samples, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='references'\n",
    "folder_paths = ['/AI',\"/Real\" ]\n",
    "test=[]\n",
    "for i in range(2):\n",
    "  folder_paths[i]=folder_path+folder_paths[i]\n",
    "# Iterate over the folder paths\n",
    "for i, folder_path in enumerate(folder_paths):\n",
    "    # Get a list of all image files in the folder\n",
    "  image_files = [file for file in os.listdir(folder_path) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "  for j, file in enumerate(image_files):\n",
    "    image_path=os.path.join(folder_path,file)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)[..., ::-1]\n",
    "    img = cv2.resize(img, (W, H))\n",
    "    # plt.imshow(img)\n",
    "    if(\"AI\" in folder_paths[i]):\n",
    "        sample=Sample(img=img,label=3)\n",
    "        samples.append(sample)\n",
    "        test.append(sample)\n",
    "    else:\n",
    "        sample=Sample(img=img,label=0)\n",
    "        samples.append(sample)\n",
    "        test.append(sample)\n",
    "  print(np.array(samples).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[3].torch_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "def color_histogram(img : np.array, norm : bool = True) -> np.array:\n",
    "    \"\"\" Count the multi-channel histogram\n",
    "\n",
    "    Params:\n",
    "        img:\n",
    "            An image with size of H x W x C.\n",
    "        norm:\n",
    "            Whether normalize the sum of the histogram for each channel to 1.\n",
    "    \"\"\"\n",
    "    hists=[]\n",
    "    for i in range(3):\n",
    "      hists.append(np.array([len(img[...,i][img[...,i]==k]) for k in range(256)])/np.size(img))\n",
    "    return np.array(hists)\n",
    "# axs.figure(figsize=(10, 3))\n",
    "axs[0,0].set_title('Real')\n",
    "axs[0,0].imshow(validation[0].img)\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "hists = color_histogram(validation[0].img)\n",
    "display(type(hists[0]))\n",
    "# ##TODO for plot\n",
    "# axs[0,1].set_title('RGB')\n",
    "axs[0,1].plot(range(256),hists[0],c='r')\n",
    "axs[0,1].plot(range(256),hists[1],c='g')\n",
    "axs[0,1].plot(range(256),hists[2],c='b')\n",
    "axs[1,0].imshow(validation[1].img)\n",
    "axs[1, 0].axis('off')\n",
    "axs[0,2].set_title('Gen-Cartoon')\n",
    "axs[0,2].imshow(validation[5].img)\n",
    "axs[0,2].axis('off')\n",
    "# axs[0,3].set_title('histogram (RGB)')\n",
    "hists = color_histogram(validation[5].img)\n",
    "display(type(hists[0]))\n",
    "# ##TODO for plot\n",
    "axs[0,3].plot(range(256),hists[0],c='r')\n",
    "axs[0,3].plot(range(256),hists[1],c='g')\n",
    "axs[0,3].plot(range(256),hists[2],c='b')\n",
    "axs[1,0].set_title('Gen-No Style')\n",
    "axs[1,0].imshow(validation[1].img)\n",
    "axs[1, 0].axis('off')\n",
    "# axs[1,1].set_title('histogram (RGB)')\n",
    "hists = color_histogram(validation[1].img)\n",
    "display(type(hists[0]))\n",
    "# ##TODO for plot\n",
    "axs[1,1].plot(range(256),hists[0],c='r')\n",
    "axs[1,1].plot(range(256),hists[1],c='g')\n",
    "axs[1,1].plot(range(256),hists[2],c='b')\n",
    "axs[1,2].set_title('Gen-Cyberpunk')\n",
    "axs[1,2].imshow(validation[11].img)\n",
    "axs[1, 2].axis('off')\n",
    "# axs[1,3].set_title('histogram (RGB)')\n",
    "hists = color_histogram(validation[11].img)\n",
    "display(type(hists[0]))\n",
    "# ##TODO for plot\n",
    "axs[1,3].plot(range(256),hists[0],c='r')\n",
    "axs[1,3].plot(range(256),hists[1],c='g')\n",
    "axs[1,3].plot(range(256),hists[2],c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to build test the model based on Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDytsd0BS3AT"
   },
   "outputs": [],
   "source": [
    "train_feats = [sample.torch_img.numpy() for sample in train]\n",
    "train_labels = [sample.label for sample in train]\n",
    "validation_feats = [sample.torch_img.numpy() for sample in validation]\n",
    "validation_labels = [sample.label for sample in validation]\n",
    "test_feats=[sample.torch_img.numpy() for sample in test]\n",
    "test_labels=[sample.label for sample in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1h1kIJRlnaPT"
   },
   "outputs": [],
   "source": [
    "num_cats=4\n",
    "temp_cats = [[0] * num_cats for _ in range(len(train_labels))]\n",
    "for i in range(len(train_labels)):\n",
    "  temp_cats[i][train_labels[i]]=1\n",
    "train_cats=temp_cats\n",
    "temp_cats = [[0] * num_cats for _ in range(len(validation_labels))]\n",
    "for i in range(len(validation_labels)):\n",
    "  temp_cats[i][validation_labels[i]]=1\n",
    "val_cats=temp_cats\n",
    "temp_cats = [[0] * num_cats for _ in range(len(test_labels))]\n",
    "for i in range(len(test_labels)):\n",
    "  temp_cats[i][test_labels[i]]=1\n",
    "test_cats=temp_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "train_feats = torch.tensor(train_feats).to(torch.float32)\n",
    "train_x = torch.reshape(train_feats,[train_feats.shape[0],3,256,341])\n",
    "train_y = torch.tensor(train_cats).to(torch.float32)\n",
    "val_feats = torch.tensor(validation_feats).to(torch.float32)\n",
    "val_x = torch.reshape(val_feats,[val_feats.shape[0],3,256,341])\n",
    "val_y = torch.tensor(val_cats).to(torch.float32)\n",
    "# test_feats = torch.tensor(test_feats).to(torch.float32)\n",
    "# test_x = torch.reshape(test_feats,[test_feats.shape[0],3,256,341])\n",
    "# test_y = torch.tensor(test_cats).to(torch.float32)\n",
    "# Specify batch size\n",
    "batch_size = 32\n",
    "num_batches = len(train_x) // batch_size\n",
    "num_epochs=200\n",
    "output_channel=4\n",
    "class SIMPLENN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SIMPLENN, self).__init__()\n",
    "        #because the shape of the image is gray image, so the input chaneel should be 1\n",
    "        self.conv1 = nn.Conv2d(3,6,kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6,16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.linear1 = nn.Linear(80032, 4096)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(4096,200)\n",
    "        self.linear3 = nn.Linear(200,4)\n",
    "    # forward function is inherted from parent's class. x denotes the input feature.\n",
    "    def forward(self, x):\n",
    "        y_pred = self.conv1(x)\n",
    "        y_pred = F.relu(y_pred)\n",
    "        y_pred = self.pool1(y_pred)\n",
    "        y_pred = F.relu(self.conv2(y_pred))\n",
    "        y_pred = self.pool2(y_pred)\n",
    "        y_pred = y_pred.view(-1,80032)\n",
    "\n",
    "        y_pred = F.relu(self.linear1(y_pred))\n",
    "        y_pred = self.linear2(y_pred)\n",
    "        y_pred = self.drop1(y_pred)\n",
    "        y_pred = self.linear3(F.relu(y_pred))\n",
    "        return y_pred\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# create model\n",
    "model = SIMPLENN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create optimizer. 1st parameter: the parameters will be optimized; 2nd: learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "train_conv=[]\n",
    "# Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx + 1) * batch_size\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(train_x[start_idx:end_idx]).cuda()\n",
    "            target = Variable(train_y[start_idx:end_idx]).cuda()\n",
    "        else:\n",
    "            inputs = Variable(train_x[start_idx:end_idx])\n",
    "            target = Variable(train_y[start_idx:end_idx])\n",
    "                # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        out= model(inputs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, target)\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        # Updating parameters via SGD\n",
    "        optimizer.step()\n",
    "        # Print training progress\n",
    "        if(batch_idx==num_batches-1):\n",
    "          print(f\"Batch {batch_idx+1}/{num_batches} - Loss: {loss.item()}\")\n",
    "    if(loss<0.001):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(val_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_values = np.argmax(out.detach().cpu().numpy(), axis=1)\n",
    "true_labels=[]\n",
    "for label in validation_labels:\n",
    "    if(label>1):\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "pred_labels=[]\n",
    "for label in max_values:\n",
    "    if(label>1):\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "# accuracy = accuracy_score(pred_labels, true_labels)\n",
    "accuracy = accuracy_score(max_values, validation_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(test_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_values = np.argmax(out.detach().cpu().numpy(), axis=1)\n",
    "true_labels=[]\n",
    "for label in test_labels:\n",
    "    if(label>1):\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "pred_labels=[]\n",
    "for label in max_values:\n",
    "    if(label>1):\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "# accuracy = accuracy_score(pred_labels, true_labels)\n",
    "accuracy = accuracy_score(max_values, test_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndXAhewreyxX"
   },
   "source": [
    "# Try to extract features by VGG16 net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_LM2CEe02X7",
    "outputId": "33a35a34-0238-4495-fdbd-36caa8f57033"
   },
   "outputs": [],
   "source": [
    "len(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yiFgKQeUVDk",
    "outputId": "88859964-31e1-44af-c375-3c44ac202fe3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models as models\n",
    "from torch.autograd import Variable\n",
    "train_feats = torch.tensor(train_feats).to(torch.float32)\n",
    "train_x = torch.reshape(train_feats,[train_feats.shape[0],3,256,341])\n",
    "val_feats = torch.tensor(validation_feats).to(torch.float32)\n",
    "val_x = torch.reshape(val_feats,[val_feats.shape[0],3,256,341])\n",
    "train_y = torch.tensor(train_cats).to(torch.float32)\n",
    "val_y = torch.tensor(val_cats).to(torch.float32)\n",
    "# load a pretrained DCNN (e.g., VGG)\n",
    "class VGGFeature(nn.Module):\n",
    "    def __init__(self, pretrained=True, layer=28):\n",
    "        super().__init__()\n",
    "        self.net = models.vgg16(pretrained).features.eval()\n",
    "        self.layer = layer\n",
    "\n",
    "        self.layer1 = nn.Linear(512*21*16, 512)\n",
    "        self.layer2 = nn.Linear(512,64)\n",
    "        self.layer3 = nn.Linear(64,4)\n",
    "        self.drop1=nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "      for idx, layer in enumerate(self.net):\n",
    "          x = layer(x)\n",
    "          if idx == self.layer:\n",
    "              break\n",
    "      y_pred=x.view(-1,512*21*16)\n",
    "      y_pred=F.relu(y_pred)\n",
    "      y_pred=self.layer1(y_pred)\n",
    "      y_pred=F.relu(y_pred)\n",
    "      train_conv=y_pred\n",
    "      y_pred=self.layer2(y_pred)\n",
    "      # y_pred=self.drop1(y_pred)\n",
    "      y_pred=F.relu(y_pred)\n",
    "      y_pred=self.layer3(y_pred)\n",
    "      return y_pred,train_conv\n",
    "force_cpu = False\n",
    "\n",
    "if torch.cuda.is_available() and not force_cpu:\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('We are using device', device)\n",
    "\n",
    "VGG = VGGFeature().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create optimizer. 1st parameter: the parameters will be optimized; 2nd: learning rate\n",
    "optimizer = torch.optim.SGD(VGG.parameters(), lr=0.05)\n",
    "train_conv=[]\n",
    "batch_size = 16\n",
    "num_batches = len(train_feats) // batch_size\n",
    "num_epochs=50\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "best_loss=100\n",
    "# Define the training loop\n",
    "counter=0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    running_train_loss = 0.0\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx + 1) * batch_size\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(train_x[start_idx:end_idx]).cuda()\n",
    "            target = Variable(train_y[start_idx:end_idx]).cuda()\n",
    "        else:\n",
    "            inputs = Variable(train_x[start_idx:end_idx])\n",
    "            target = Variable(train_y[start_idx:end_idx])\n",
    "                # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        out,_= VGG(inputs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, target)\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "        # Updating parameters via SGD\n",
    "        optimizer.step()\n",
    "        # Print training progress\n",
    "        if(batch_idx==num_batches-1):\n",
    "          print(f\"Batch {batch_idx+1}/{num_batches} - Loss: {loss.item()}\")\n",
    "        running_train_loss += loss.item()\n",
    "    epoch_train_loss = running_train_loss / train_x.shape[0]\n",
    "    train_loss_values.append(epoch_train_loss)\n",
    "    # Validation phase\n",
    "    VGG.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_outputs,_ = VGG(val_x)\n",
    "        val_loss = criterion(val_outputs, val_y)\n",
    "        running_val_loss += val_loss.item()\n",
    "    len_val=15\n",
    "    # # Calculate average validation loss for the epoch\n",
    "    epoch_val_loss = running_val_loss / len_val\n",
    "    val_loss_values.append(epoch_val_loss)\n",
    "    if(running_val_loss<best_loss):\n",
    "        best_loss=running_val_loss\n",
    "        best_model=VGG\n",
    "        counter=0\n",
    "    else:\n",
    "        counter+=1\n",
    "    if(counter>5):\n",
    "        break\n",
    "    # Print the loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} - Training Loss: {epoch_train_loss}, Validation Loss: {epoch_val_loss}\")\n",
    "\n",
    "# Plot the loss values for training and validation sets on the same chart\n",
    "plt.plot(train_loss_values, marker='o', label='Training Loss')\n",
    "plt.plot(val_loss_values, marker='o', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during Training and Validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ2xMoeV3btc",
    "outputId": "eb46efb3-31dd-407c-fbe0-1d0037fbd666"
   },
   "outputs": [],
   "source": [
    "train_out,train_conv=best_model(train_x)\n",
    "val_out,val_conv = best_model(val_x)\n",
    "test_out,test_conv = best_model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss values for training and validation sets on the same chart\n",
    "plt.plot(train_loss_values, marker='', label='Training Loss')\n",
    "plt.plot(val_loss_values, marker='', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss during Training and Validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrFnTBIA3eFs",
    "outputId": "8464196c-9e18-4139-efcd-2948d0f6fe8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "out,_= best_model(test_x)\n",
    "max_values = np.argmax(out.detach().numpy(), axis=1)\n",
    "true_labels=[]\n",
    "for label in test_labels:\n",
    "    if(label>1):\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "pred_labels=[]\n",
    "for label in max_values:\n",
    "    if(label>1):\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "# accuracy = accuracy_score(pred_labels, true_labels)\n",
    "accuracy = accuracy_score(max_values, test_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM + VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conv=train_conv.detach().cpu().requires_grad_(False)\n",
    "ind=0\n",
    "for conv in train_conv.numpy():\n",
    "  train[ind].vgg_feat=conv\n",
    "  ind+=1\n",
    "val_conv=val_conv.detach().cpu()\n",
    "ind=0\n",
    "for conv in val_conv.numpy():\n",
    "  validation[ind].vgg_feat=conv\n",
    "  ind+=1\n",
    "ind=0\n",
    "test_conv=test_conv.detach().cpu().requires_grad_(False)\n",
    "for conv in test_conv.numpy():\n",
    "  test[ind].vgg_feat=conv\n",
    "  ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_feat=[sample.vgg_feat for sample in train]\n",
    "train_label=[sample.label for sample in train]\n",
    "val_feat=[sample.vgg_feat for sample in validation]\n",
    "val_label=[sample.label for sample in validation]\n",
    "test_feat=[sample.vgg_feat for sample in test]\n",
    "test_label=[sample.label for sample in test]\n",
    "# 3. Model Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# svm_classifier = svm.SVC(kernel='linear')\n",
    "svm_classifier = RandomForestClassifier()\n",
    "svm_classifier.fit(train_feat, train_label)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "y_pred = svm_classifier.predict(val_feat)\n",
    "accuracy = accuracy_score(val_label, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # 5. Prediction\n",
    "# # Assuming you have a new, unseen image represented by its features stored in a variable called 'new_image_features'\n",
    "predicted_class = svm_classifier.predict(val_feat)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"True class\",val_label)\n",
    "\n",
    "# 4. Model test\n",
    "y_pred = svm_classifier.predict(test_feat)\n",
    "accuracy = accuracy_score(test_label, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# # 5. Prediction\n",
    "# # Assuming you have a new, unseen image represented by its features stored in a variable called 'new_image_features'\n",
    "predicted_class = svm_classifier.predict(test_feat)\n",
    "print(\"Test Predicted Class:\", predicted_class)\n",
    "print(\"Test True class\",test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "correct=0\n",
    "for result in test_label:\n",
    "    if(result==0):\n",
    "        if(predicted_class[i]==0):\n",
    "            correct+=1\n",
    "    elif(result!=0):\n",
    "        if(predicted_class[i]!=0):\n",
    "            correct+=1\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct/len(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Feature extract + Patchify + Siamonse network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def patchify_image(image, patch_size):\n",
    "    '''\n",
    "    Patchify a colorful image into non-overlapping patches.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image as a NumPy array.\n",
    "        patch_size (tuple): Size of the patches (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Patchified image as a 4D array with shape (num_patches, patch_height, patch_width, num_channels).\n",
    "    '''\n",
    "    height, width, channels = image.shape\n",
    "    patch_height, patch_width = patch_size\n",
    "\n",
    "    num_patches_h = height // patch_height\n",
    "    num_patches_w = width // patch_width\n",
    "    num_patches = num_patches_h * num_patches_w\n",
    "\n",
    "    patchified_image = np.zeros((num_patches, patch_height, patch_width, channels), dtype=image.dtype)\n",
    "\n",
    "    index = 0\n",
    "    for h in range(num_patches_h):\n",
    "        for w in range(num_patches_w):\n",
    "            patch = image[h*patch_height:(h+1)*patch_height, w*patch_width:(w+1)*patch_width, :]\n",
    "            patchified_image[index] = patch\n",
    "            index += 1\n",
    "\n",
    "    return patchified_image\n",
    "\n",
    "\n",
    "# Load the colorful image\n",
    "image = train[1].img\n",
    "\n",
    "# Define patch size and overlap\n",
    "# Convert image to RGB if needed\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Define patch size\n",
    "patch_size = (1008,1344)\n",
    "\n",
    "# Patchify the image\n",
    "patchified_image = patchify_image(image, patch_size)\n",
    "\n",
    "# Display different patches\n",
    "num_patches_to_show = 9\n",
    "\n",
    "# Create a 4x4 subplot grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 16))\n",
    "\n",
    "# Iterate over the patchified images and display them in the grid\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(patchified_image[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of patchified images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the set for patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSample:\n",
    "    def __init__(self, idx=0, fname='', img=None, feat=None, label=None):\n",
    "        self.idx = idx\n",
    "        self.feat=feat\n",
    "        self.img = img\n",
    "#         self.torch_img=img\n",
    "        self.label = label\n",
    "        self.pred_set = []\n",
    "        self.si_score = []\n",
    "        self.pred = None\n",
    "import gc\n",
    "i=0\n",
    "patch_train=[]\n",
    "for sample in train:\n",
    "    sample.patches=patchify_image(sample.img, (1008,1344))\n",
    "    torch_patch=[]\n",
    "    for patch in sample.patches:\n",
    "#         print(img_transform(patch, inference_transform).shape)\n",
    "        _,conv=best_model(img_transform(patch, inference_transform))\n",
    "        torch_patch.append(torch.squeeze(conv).detach().requires_grad_(False))\n",
    "        patch_train.append(SubSample(idx=i,img=patch,feat=torch_patch[-1],label=sample.label))\n",
    "    gc.collect()\n",
    "    sample.patches=torch_patch\n",
    "#     print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_val=[]\n",
    "for sample in validation:\n",
    "    sample.patches=patchify_image(sample.img, (1008,1344))\n",
    "    torch_patch=[]\n",
    "    for patch in sample.patches:\n",
    "#         print(img_transform(patch, inference_transform).shape)\n",
    "        _,conv=best_model(img_transform(patch, inference_transform))\n",
    "        torch_patch.append(torch.squeeze(conv).detach().requires_grad_(False))\n",
    "        patch_val.append(SubSample(idx=i,img=patch,feat=torch_patch[-1],label=sample.label))\n",
    "    gc.collect()\n",
    "    sample.patches=torch_patch\n",
    "#     print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_test=[]\n",
    "for sample in test:\n",
    "    sample.patches=patchify_image(sample.img, (1008,1344))\n",
    "    torch_patch=[]\n",
    "    for patch in sample.patches:\n",
    "#         print(img_transform(patch, inference_transform).shape)\n",
    "        _,conv=best_model(img_transform(patch, inference_transform))\n",
    "        torch_patch.append(torch.squeeze(conv).detach().requires_grad_(False))\n",
    "        patch_test.append(SubSample(idx=i,img=patch,feat=torch_patch[-1],label=sample.label))\n",
    "    gc.collect()\n",
    "    sample.patches=torch_patch\n",
    "#     print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "i=0\n",
    "for sample in samples:\n",
    "    sample.patches=patchify_image(sample.img, (1008,1344))\n",
    "    torch_patch=[]\n",
    "    for patch in sample.patches:\n",
    "#         print(img_transform(patch, inference_transform).shape)\n",
    "        _,conv=best_model(img_transform(patch, inference_transform))\n",
    "        torch_patch.append(torch.squeeze(conv).detach().requires_grad_(False))\n",
    "    gc.collect()\n",
    "    sample.patches=torch_patch\n",
    "#     print(i)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Train for Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = torch.empty(0, 512)\n",
    "train_cats =[]\n",
    "\n",
    "for sample in train:\n",
    "    stacked = torch.stack(sample.patches, dim=0)\n",
    "#     print(stacked.shape)\n",
    "    train_feats = torch.cat([stacked, train_feats], dim=0)\n",
    "    cat=[sample.label for c in range(9)]\n",
    "    train_cats.append(cat)\n",
    "train_cats=torch.from_numpy(np.array(train_cats).flatten())\n",
    "# Generate random permutation indices\n",
    "indices = torch.randperm(len(train_cats))\n",
    "\n",
    "# Shuffle both tensor arrays using the generated indices\n",
    "train_feats = train_feats[indices]\n",
    "train_cats = train_cats[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].patches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# build the networks\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, in_features=512, mid_features=256, out_features=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('Input', nn.Linear(in_features, out_features)),\n",
    "#             ('Act', nn.ReLU()),\n",
    "#             ('Output', nn.Linear(mid_features, out_features)),\n",
    "        ]))\n",
    "        self.cos_sim = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        feat_x = self.net(x)\n",
    "        feat_y = self.net(y)\n",
    "#         print(feat_x.shape)\n",
    "#         print(self.cos_sim(feat_x, feat_y))\n",
    "        return self.cos_sim(feat_x, feat_y)\n",
    "\n",
    "Net = SiameseNet().to(device)\n",
    "optimizer = torch.optim.Adam(Net.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_iters = 100000\n",
    "batch_size = 32\n",
    "n_train = len(train_feats)\n",
    "# train_inputs = torch.cat([sample. for sample in train], dim=0).to(device)\n",
    "# train_labels = torch.tensor([sample.label for sample in train]).to(device)\n",
    "\n",
    "# print(train_inputs.shape, train_labels.shape)\n",
    "# training\n",
    "best_loss=100\n",
    "for it in range(num_iters):\n",
    "    idx_x = torch.randint(n_train, size=(batch_size,), device=device)\n",
    "    idx_y = torch.randint(n_train, size=(batch_size,), device=device)\n",
    "    \n",
    "    input_x = train_feats[idx_x]\n",
    "    input_y = train_feats[idx_y]\n",
    "    target = (train_cats[idx_x] == train_cats[idx_y]).to(torch.float32) * 2 - 1\n",
    "    output = Net(input_x, input_y)\n",
    "    # print(output, target)\n",
    "    loss = criterion(output, target)\n",
    "    if(loss<best_loss):\n",
    "        best_loss=loss\n",
    "        best_Net=Net\n",
    "    if it % 10000 == 0:\n",
    "        print(loss.item())\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build histogram for whole image(Siamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for sample in train:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros(len(train))\n",
    "    i+=1\n",
    "for sample in validation:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros(len(train))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_feats = torch.cat([feat.view(1, -1) for feat in train_feats], dim=0)\n",
    "best_Net.eval()\n",
    "for idx, sample in enumerate(patch_train):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    \n",
    "    for i, order in enumerate(orders[1:6]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        train[sample.idx].si_score[result.idx]+=dists[order]\n",
    "#         plt.title(f'mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break\n",
    "for idx, sample in enumerate(patch_val):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    \n",
    "    for i, order in enumerate(orders[1:6]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        validation[sample.idx-len(train)].si_score[result.idx]+=dists[order]\n",
    "#         plt.title(f'label{category[sample.label]}mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "for idx in range(len(validation[0].si_score)):\n",
    "    label.append(train[idx].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=[]\n",
    "# Example data\n",
    "x_values = label\n",
    "y_values = validation[0].si_score\n",
    "k=0\n",
    "for value in x_values:\n",
    "    if(value==0):\n",
    "        k+=1\n",
    "        color.append(\"orange\")\n",
    "    if(value==1):\n",
    "        color.append(\"black\")\n",
    "    if(value==2):\n",
    "        color.append(\"purple\")\n",
    "    if(value==3):\n",
    "        color.append(\"yellow\")\n",
    "# Generate x-axis tick positions\n",
    "# x_tick_positions = range(len(x_values))\n",
    "\n",
    "# # Sort x_values and update y_values accordingly\n",
    "# sorted_data = sorted(zip(x_values, y_values))\n",
    "# x_values, y_values = zip(*sorted_data)\n",
    "\n",
    "# Generate x-axis tick positions\n",
    "x_tick_positions = range(len(x_values))\n",
    "\n",
    "# Plot the bars\n",
    "plt.bar(x_tick_positions, y_values,color=color)\n",
    "\n",
    "# Set x-axis tick positions and labels\n",
    "plt.xticks(x_tick_positions, x_values)\n",
    "\n",
    "# Set x-axis and y-axis labels\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylabel('Categories')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify different patches independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for sample in train:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros((9,len(train)))\n",
    "    i+=1\n",
    "for sample in validation:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros((9,len(train)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = torch.cat([feat.view(1, -1) for feat in train_feats], dim=0)\n",
    "best_Net.eval()\n",
    "p=0\n",
    "for idx, sample in enumerate(patch_train):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    if(p==9):\n",
    "        p=0\n",
    "    for i, order in enumerate(orders[1:56]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        train[sample.idx].si_score[p][result.idx]+=1\n",
    "    p+=1\n",
    "#         plt.title(f'mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break\n",
    "p=0\n",
    "for idx, sample in enumerate(patch_val):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    if(p==9):\n",
    "        p=0\n",
    "    for i, order in enumerate(orders[1:56]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        validation[sample.idx-len(train)].si_score[p][result.idx]+=1\n",
    "    p+=1\n",
    "#         plt.title(f'label{category[sample.label]}mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train and val feats(with SVM and RFC classifier, Siamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_train_feat=train[0].si_score\n",
    "si_train_label=[]\n",
    "si_train_label.append([train[0].label for i in range(9)])\n",
    "for sample in train[1:]:\n",
    "    si_train_feat=np.vstack((si_train_feat,sample.si_score))\n",
    "    si_train_label.append([sample.label for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_train_label=np.array(si_train_label).reshape(9*len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_val_feat=validation[0].si_score\n",
    "si_val_label=[]\n",
    "si_val_label.append([validation[0].label for i in range(9)])\n",
    "for sample in validation[1:]:\n",
    "    si_val_feat=np.vstack((si_val_feat,sample.si_score))\n",
    "    si_val_label.append([sample.label for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_val_label=np.array(si_val_label).reshape(9*len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create an instance of SVM classifier\n",
    "# classifier = SVC(kernel='poly',degree=3)\n",
    "classifier = RandomForestClassifier()\n",
    "# Train the classifier\n",
    "classifier.fit(si_train_feat, si_train_label)\n",
    "\n",
    "predictions = classifier.predict(si_val_feat)\n",
    "print(\"Predictions:\", predictions)\n",
    "accuracy = accuracy_score(si_val_label, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote=predictions.reshape(15,9)\n",
    "\n",
    "index=0\n",
    "for result in vote:\n",
    "    real=0\n",
    "    nostyle=0\n",
    "    cyberpunk=0\n",
    "    cartoon=0\n",
    "    for expert in result:\n",
    "        if (expert==0):\n",
    "            real+=1\n",
    "        elif(expert==1):\n",
    "            cyberpunk+=1\n",
    "        elif(expert==2):\n",
    "            cartoon+=1\n",
    "        else:\n",
    "            nostyle+=1\n",
    "    if(real>=5):\n",
    "        validation[index].pred=0\n",
    "    else:\n",
    "        if cyberpunk >= cartoon and cyberpunk >= nostyle:\n",
    "            validation[index].pred=1\n",
    "        elif cartoon >= cyberpunk and cartoon >= nostyle:\n",
    "            validation[index].pred=2\n",
    "        else:\n",
    "            validation[index].pred=3\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[sample.pred for sample in validation]\n",
    "true=[sample.label for sample in validation]\n",
    "accuracy = accuracy_score(pred, true)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard voting(Siamese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for sample in train:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros((9,4))\n",
    "    i+=1\n",
    "for sample in validation:\n",
    "    sample.idx=i\n",
    "    sample.si_score=np.zeros((9,4))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = torch.cat([feat.view(1, -1) for feat in train_feats], dim=0)\n",
    "best_Net.eval()\n",
    "p=0\n",
    "for idx, sample in enumerate(patch_train):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    if(p==9):\n",
    "        p=0\n",
    "    for i, order in enumerate(orders[1:6]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        train[sample.idx].si_score[p][train[result.idx].label]+=1\n",
    "    p+=1\n",
    "#         plt.title(f'mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break\n",
    "p=0\n",
    "for idx, sample in enumerate(patch_val):\n",
    "    dists =  best_Net(sample.feat.view(1, -1).expand_as(all_feats), all_feats)\n",
    "    simlarity, orders = torch.sort(dists, descending=True)\n",
    "\n",
    "#     plt.figure(figsize=(18,4))\n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.title(f'query:label:{category[sample.label]} idx{sample.idx}')\n",
    "#     plt.imshow(sample.img)\n",
    "    if(p==9):\n",
    "        p=0\n",
    "    for i, order in enumerate(orders[1:6]):\n",
    "#         plt.subplot(1, 6, i+2)\n",
    "        result = patch_train[order]\n",
    "        validation[sample.idx-len(train)].si_score[p][train[result.idx].label]+=1\n",
    "    p+=1\n",
    "#         plt.title(f'label{category[sample.label]}mark:{dists[order]}')\n",
    "#         plt.imshow(result.img)\n",
    "#     if(idx>5):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation[0].si_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "for sample in validation:\n",
    "    real=0\n",
    "    nostyle=0\n",
    "    cyberpunk=0\n",
    "    cartoon=0\n",
    "    sample.pred=[]\n",
    "    for patch in sample.si_score:\n",
    "        patch_pred = np.argmax(patch)\n",
    "        sample.pred.append(patch_pred)\n",
    "    real=0\n",
    "    nostyle=0\n",
    "    cyberpunk=0\n",
    "    cartoon=0\n",
    "    for ppred in sample.pred:\n",
    "        if (ppred==0):\n",
    "            real+=1\n",
    "        elif(ppred==1):\n",
    "            cyberpunk+=1\n",
    "        elif(ppred==2):\n",
    "            cartoon+=1\n",
    "        else:\n",
    "            nostyle+=1\n",
    "    if(real>=5):\n",
    "        validation[index].pred=0\n",
    "    else:\n",
    "        if cyberpunk >= cartoon and cyberpunk >= nostyle:\n",
    "            validation[index].pred=1\n",
    "        elif cartoon >= cyberpunk and cartoon >= nostyle:\n",
    "            validation[index].pred=2\n",
    "        else:\n",
    "            validation[index].pred=3\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[sample.pred for sample in validation]\n",
    "true=[sample.label for sample in validation]\n",
    "accuracy = accuracy_score(pred, true)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly using VGG feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat=patch_train[0].feat\n",
    "i=0\n",
    "for sample in patch_train[1:]:\n",
    "    train_feat=np.vstack((train_feat,sample.feat))\n",
    "    \n",
    "val_feat=patch_val[0].feat\n",
    "for sample in patch_val[1:]:\n",
    "    val_feat=np.vstack((val_feat,sample.feat))\n",
    "\n",
    "test_feat=patch_test[0].feat\n",
    "for sample in patch_test[1:]:\n",
    "    test_feat=np.vstack((test_feat,sample.feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feat=np.concatenate((train_feat, val_feat), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat=[sample.feat for sample in patch_train]\n",
    "train_label=np.array([sample.label for sample in patch_train])\n",
    "# val_feat=[sample.feat for sample in patch_val]\n",
    "val_label=np.array([sample.label for sample in patch_val]) \n",
    "# test_feat = [sample.feat for sample in patch_test]\n",
    "test_label = np.array([sample.label for sample in patch_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat=np.concatenate((train_feat, val_feat), axis=0)\n",
    "all_label=np.concatenate((train_label,val_label), axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Set the number of folds\n",
    "k = 10\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=69)\n",
    "# classifier = SVC(kernel='linear')\n",
    "accuracies=[]\n",
    "best_accuracy=0\n",
    "classifier = RandomForestClassifier()\n",
    "# Iterate over the folds\n",
    "for train_index, test_index in kf.split(all_feat):\n",
    "    train_x, val_x = all_feat[train_index], all_feat[test_index]\n",
    "    train_y, val_y = all_label[train_index], all_label[test_index]\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    predictions = classifier.predict(val_x)\n",
    "#     print(\"Predictions:\", predictions)\n",
    "    accuracy = accuracy_score(val_y, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    if(accuracy>best_accuracy):\n",
    "        best_accuracy=accuracy\n",
    "        best_model=classifier\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack classifier+voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Define the individual classifiers\n",
    "classifier_1 = LogisticRegression()\n",
    "classifier_2 = RandomForestClassifier()\n",
    "classifier_3 = SVC(probability=True)\n",
    "\n",
    "\n",
    "# Set the number of folds\n",
    "k = 10\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=69)\n",
    "# classifier = SVC(kernel='linear')\n",
    "accuracies=[]\n",
    "best_accuracy=0\n",
    "# Create the voting classifier\n",
    "voting_classifier = VotingClassifier([('random_forest', classifier_2), ('svm', classifier_3)],\n",
    "    voting='soft'  # Use majority voting\n",
    ")\n",
    "\n",
    "# Train the voting classifier using the training data\n",
    "voting_classifier.fit(train_feat, train_label)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = np.argmax(voting_classifier.predict_proba(val_feat),axis=1)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(val_label, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "for train_index, test_index in kf.split(all_feat):\n",
    "    train_x, val_x = all_feat[train_index], all_feat[test_index]\n",
    "    train_y, val_y = all_label[train_index], all_label[test_index]\n",
    "\n",
    "    # Train the voting classifier using the training data\n",
    "    voting_classifier.fit(train_feat, train_label)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = np.argmax(voting_classifier.predict_proba(val_feat),axis=1)\n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = accuracy_score(val_label, predictions)\n",
    "    if(accuracy>best_accuracy):\n",
    "        best_accuracy=accuracy\n",
    "        best_model=voting_classifier\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=voting_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of values\n",
    "\n",
    "# Generate x-axis values based on the index of each value in the list\n",
    "x = range(len(accuracies))\n",
    "\n",
    "# Plot the line chart\n",
    "plt.plot(x, accuracies)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('K-fold Validation')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in validation:\n",
    "    patch=np.array([patch.numpy() for patch in sample.patches])\n",
    "    sample.pred=np.argmax(best_model.predict_proba(patch),axis=1)\n",
    "    print(sample.pred)\n",
    "    real=0\n",
    "    nostyle=0\n",
    "    cyberpunk=0\n",
    "    cartoon=0\n",
    "    for ppred in sample.pred:\n",
    "        if (ppred==0):\n",
    "            real+=1\n",
    "        elif(ppred==1):\n",
    "            cyberpunk+=1\n",
    "        elif(ppred==2):\n",
    "            cartoon+=1\n",
    "        else:\n",
    "            nostyle+=1\n",
    "    if(real>=5):\n",
    "        sample.pred=0\n",
    "    else:\n",
    "        if cyberpunk >= cartoon and cyberpunk >= nostyle:\n",
    "            sample.pred=1\n",
    "        elif cartoon >= cyberpunk and cartoon >= nostyle:\n",
    "            sample.pred=2\n",
    "        else:\n",
    "            sample.pred=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in test:\n",
    "    patch=np.array([patch.numpy() for patch in sample.patches])\n",
    "    sample.pred=np.argmax(best_model.predict_proba(patch),axis=1)\n",
    "    print(sample.pred)\n",
    "    real=0\n",
    "    nostyle=0\n",
    "    cyberpunk=0\n",
    "    cartoon=0\n",
    "    for ppred in sample.pred:\n",
    "        if (ppred==0):\n",
    "            real+=1\n",
    "        elif(ppred==1):\n",
    "            cyberpunk+=1\n",
    "        elif(ppred==2):\n",
    "            cartoon+=1\n",
    "        else:\n",
    "            nostyle+=1\n",
    "    if(real>=5):\n",
    "        sample.pred=0\n",
    "    else:\n",
    "        if cyberpunk >= cartoon and cyberpunk >= nostyle:\n",
    "            sample.pred=1\n",
    "        elif cartoon >= cyberpunk and cartoon >= nostyle:\n",
    "            sample.pred=2\n",
    "        else:\n",
    "            sample.pred=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[sample.pred for sample in validation]\n",
    "true=[sample.label for sample in validation]\n",
    "accuracy = accuracy_score(pred, true)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[sample.pred for sample in test]\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]!=0):\n",
    "        pred[i]=3\n",
    "true=[sample.label for sample in test]\n",
    "accuracy = accuracy_score(pred, true)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_classified=[]\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]!=true[i]):\n",
    "        mis_classified.append(Image.fromarray(test[i].img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mis_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16, 16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if(i<5):\n",
    "        ax.set_title(f'Gen-Nostyle')\n",
    "    else:\n",
    "        ax.set_title(f'Real')\n",
    "    ax.imshow(mis_classified[i])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(test[5].img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def patchify_image(image, patch_size):\n",
    "    '''\n",
    "    Patchify a colorful image into non-overlapping patches.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): Input image as a NumPy array.\n",
    "        patch_size (tuple): Size of the patches (height, width).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Patchified image as a 4D array with shape (num_patches, patch_height, patch_width, num_channels).\n",
    "    '''\n",
    "    height, width, channels = image.shape\n",
    "    patch_height, patch_width = patch_size\n",
    "\n",
    "    num_patches_h = height // patch_height\n",
    "    num_patches_w = width // patch_width\n",
    "    num_patches = num_patches_h * num_patches_w\n",
    "\n",
    "    patchified_image = np.zeros((num_patches, patch_height, patch_width, channels), dtype=image.dtype)\n",
    "\n",
    "    index = 0\n",
    "    for h in range(num_patches_h):\n",
    "        for w in range(num_patches_w):\n",
    "            patch = image[h*patch_height:(h+1)*patch_height, w*patch_width:(w+1)*patch_width, :]\n",
    "            patchified_image[index] = patch\n",
    "            index += 1\n",
    "\n",
    "    return patchified_image\n",
    "\n",
    "sample=validation[11]\n",
    "# Load the colorful image\n",
    "image = sample.img\n",
    "\n",
    "# Define patch size and overlap\n",
    "# Convert image to RGB if needed\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Define patch size\n",
    "patch_size = (1008,1344)\n",
    "\n",
    "# Patchify the image\n",
    "patchified_image = patchify_image(image, patch_size)\n",
    "\n",
    "# Display different patches\n",
    "num_patches_to_show = 9\n",
    "\n",
    "# Create a 4x4 subplot grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 16))\n",
    "\n",
    "# Iterate over the patchified images and display them in the grid\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_title(f'{category[sample.pred[i]]}')\n",
    "    ax.imshow(patchified_image[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of patchified images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation[11].pred"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
