{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4162iHzHoFre"
      },
      "source": [
        "# Emoji Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "6RG59YovoH3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30d9kOpwoFrf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image, ImageFont, ImageDraw,ImageFilter\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.feature import hog\n",
        "import cv2\n",
        "%pip install torch == 1.7.0 torchvision == 0.8.0 torchaudio == 0.7.0\n",
        "%pip install -U opencv-python\n",
        "%pip install -U opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with unicode emoji"
      ],
      "metadata": {
        "id": "csF31cPazNV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolution through different direction\n",
        "def conv_horizon(img):\n",
        "  return img.filter(ImageFilter.Kernel((3, 3), (-1, -2, -1, 0, 0, 0, 1, 2, 1), 1, 0))\n",
        "def conv_vert(img):\n",
        "  return img.filter(ImageFilter.Kernel((3,3),(1,0,-1,2,0,-2,1,0,-1),1,0))\n",
        "def conv_edge(img):\n",
        "  return img.filter(ImageFilter.Kernel((3,3),(-1,-1,-1,-1,8,-1,-1,-1,-1),1,0))"
      ],
      "metadata": {
        "id": "D-ZYQZ0pIvyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI77C_fuoFrh"
      },
      "outputs": [],
      "source": [
        "def emoji_to_image(emoji: str, size: int = 64) -> np.ndarray:\n",
        "  image = Image.new(\"L\", (80,80), (255))\n",
        "  font = ImageFont.truetype(\"/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/NotoEmoji-VariableFont_wght.ttf\", 60, encoding='unic')\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  draw.textbbox(xy=[0,0], text=emoji, font=font)\n",
        "  draw.text((0, 0), emoji, fill=(0), font=font)\n",
        "\n",
        "  return np.array(image.convert('L'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization of the dataset"
      ],
      "metadata": {
        "id": "eDB6PJJBeCbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include label visualization(All about Kaggle unicode emojis)\n",
        "https://www.kaggle.com/datasets/thedevastator/analyzing-emoji-characteristics-through-unicode"
      ],
      "metadata": {
        "id": "AA72t0hlQQum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "csv_file_path = '/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/emoji_df_v2.csv'\n",
        "#Extract both columns\n",
        "column1_data = []\n",
        "column2_data = []\n",
        "\n",
        "data = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "W98H0-DfsOPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "HB1QtVO8q3CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training purpose, we need to convert all the labels into numeric value, for example:\n",
        "\n",
        "labels={0: 'face-smiling',1: 'face-affection',2: 'face-tongue',3: 'face-hand',4:'face-neutral-skeptical'}"
      ],
      "metadata": {
        "id": "rpYz1sck5Idj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories={}\n",
        "labels={}\n",
        "for i,j in zip(data[\"emoji\"],data[\"sub_group\"]):\n",
        "  categories[i]=j"
      ],
      "metadata": {
        "id": "rwj0bb4RpnRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "for k in data[\"sub_group\"]:\n",
        "  if k not in labels:\n",
        "    labels[k]=index\n",
        "    index+=1"
      ],
      "metadata": {
        "id": "2kLZd0wDFpoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to build all the training objects as a sample class for convinience, each sample represent a emoji image object"
      ],
      "metadata": {
        "id": "HYWc71SRdRqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sample:\n",
        "    def __init__(self, idx=0, cat=-1, img=None, lbp_feat=None, label=None):\n",
        "      '''\n",
        "        # idx: index of the object, img: the image corresponding to the emoji, cat: category it belongs to\n",
        "        # lbp_feat: lbp feature of the img, label: training or testing set it belongs to.\n",
        "      '''\n",
        "      self.idx = idx\n",
        "      self.cat = cat\n",
        "      self.img = img\n",
        "      self.lbp_feat=lbp_feat\n",
        "      self.label = label\n",
        "      self.conv_vert=conv_vert(Image.fromarray(self.img))\n",
        "      self.conv_horizon=conv_horizon(Image.fromarray(self.img))\n",
        "      self.conv_edge=conv_edge(Image.fromarray(self.img))\n",
        "      self.histogram=[]\n",
        "      self.conv=None\n",
        "      self.pred = None\n",
        "      self.sift_des=None\n",
        "      self.bovw_vec=None\n",
        "    def get_cat(self,cat):\n",
        "      return labels[cat]\n",
        "    def plot_images(self):\n",
        "      # Create a figure and axis with a grid layout of 1 row and 3 columns\n",
        "      fig, axs = plt.subplots(1, 4)\n",
        "      # Plot the images\n",
        "      axs[0].imshow(self.img,cmap='gray')\n",
        "      axs[0].axis('off')\n",
        "      axs[0].set_title('original')\n",
        "\n",
        "      # Plot the images\n",
        "      axs[1].imshow(np.array(self.conv_vert),cmap=\"gray\")\n",
        "      axs[1].axis('off')\n",
        "      axs[1].set_title('conv_vert')\n",
        "\n",
        "      axs[2].imshow(np.array(self.conv_horizon),cmap=\"gray\")\n",
        "      axs[2].axis('off')\n",
        "      axs[2].set_title('conv_horizon')\n",
        "\n",
        "      axs[3].imshow(np.array(self.conv_edge),cmap='gray')\n",
        "      axs[3].axis('off')\n",
        "      axs[3].set_title('conv_edge')\n",
        "\n",
        "      # Adjust the layout of the subplots\n",
        "      plt.tight_layout()\n",
        "\n",
        "      # Show the plot\n",
        "      plt.show()\n",
        "    def display_sift_results(self):\n",
        "        # Initialize the SIFT detector\n",
        "        sift = cv2.SIFT_create()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(15, 5))  # Adjust the figsize as needed\n",
        "\n",
        "        images = [self.img, self.conv_vert, self.conv_horizon, self.conv_edge]\n",
        "        titles = ['origin', 'conv_vert', 'conv_horizon', 'conv_edge']\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "\n",
        "            # Detect keypoints and compute descriptors\n",
        "            keypoints, descriptors = sift.detectAndCompute(np.array(image), None)\n",
        "\n",
        "            # Draw keypoints on the image\n",
        "            image_with_keypoints = cv2.drawKeypoints(np.array(image), keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "            # Display the image with keypoints and title\n",
        "            axs[i].imshow(image_with_keypoints, cmap='gray')\n",
        "            axs[i].set_title(titles[i])\n",
        "            axs[i].axis('off')\n",
        "\n",
        "        plt.show()\n",
        "def get_label(num):\n",
        "  for key in labels.keys():\n",
        "    if(labels[key]==num):\n",
        "      return key\n",
        "  return None"
      ],
      "metadata": {
        "id": "cj5neiovhQDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training(Execute this part when training the model)\n",
        "Following is to put all the images together"
      ],
      "metadata": {
        "id": "EdBd1FODTa3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples=[]\n",
        "index=0\n",
        "for k in categories.keys():\n",
        "  samples.append(Sample(img=emoji_to_image(k)))\n",
        "  samples[-1].cat=samples[-1].get_cat(categories[k])\n",
        "  index+=1\n",
        "train,validation= train_test_split(samples, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "IeTpspUydAsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "JcSYTkQOeSxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Following part is about testing in emoji kitchen (Do not execute if you are in training phase)"
      ],
      "metadata": {
        "id": "MPmxZ7A1RvGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build the emoji kitchen test set(Test part for unseen emoji generated by emoji kitchen)"
      ],
      "metadata": {
        "id": "4jCe8d-QvF9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples=[]\n",
        "index=0\n",
        "for k in categories.keys():\n",
        "  samples.append(Sample(img=emoji_to_image(k)))\n",
        "  samples[-1].cat=samples[-1].get_cat(categories[k])\n",
        "  index+=1"
      ],
      "metadata": {
        "id": "g1y5StD7TzA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"face-neutral\"]=2\n",
        "labels[\"emotion\"]=24"
      ],
      "metadata": {
        "id": "-BNR9BQiRa2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "src=\"/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/test_emojis\"\n",
        "file_name=[\"animal-mamal1.png\",\"hand-fingers-closed1.png\",\"face-negative1.png\",\"face-negative2.png\",\"face-positive1.png\",\n",
        "\"face-positive2.png\",\"face-positive3.png\",\"sky&weather1.png\"]\n",
        "class_name=[\"animal-mammal\",\"hand-fingers-closed\",\"face-negative\",\"face-negative\",\"face-positive\",\"face-positive\",\"face-positive\",\"sky & weather\"]\n",
        "test=[]\n",
        "for i in range(8):\n",
        "  fpath = os.path.join(src, file_name[i])\n",
        "  img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1]\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  img_gray = cv2.resize(img_gray, (80, 80))\n",
        "  _, binary_img = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
        "  test.append(Sample(img=img_gray))\n",
        "  test[-1].cat=labels[class_name[i]]\n",
        "  display(binary_img)"
      ],
      "metadata": {
        "id": "sp7wHdhY9Yf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load self collected emoji kitchen data"
      ],
      "metadata": {
        "id": "D6nWeAVTJvq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=0\n",
        "# for k in categories.keys():\n",
        "#   if(\"face\" in categories[k]):\n",
        "#     samples.append(Sample(img=emoji_to_image(k)))\n",
        "#     samples[-1].cat=samples[-1].get_cat(categories[k])\n",
        "#     index+=1\n",
        "import os\n",
        "import cv2\n",
        "folder_name=[\"face-positive\",\"face-negative\",\"face-neutral\",\"animal-mammal\",\"sky & weather\"]\n",
        "human_labels={\"face-positive\":0,\"face-negative\":1,\"face-neutral\":2,\"animal-mammal\":15,\"sky & weather\":17}\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/test_emojis/emoji_kitchen_set'\n",
        "k=1\n",
        "\n",
        "for i in range(len(folder_name)):\n",
        "  file_path = os.path.join(folder_path, folder_name[i])\n",
        "  image_files = [file for file in os.listdir(file_path)]\n",
        "  for file in enumerate(image_files):\n",
        "      fpath = os.path.join(file_path, file[1])\n",
        "      img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1]\n",
        "      img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "      img_gray = cv2.resize(img_gray, (80, 80))\n",
        "      # _, binary_img = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
        "      samples.append(Sample(img=img_gray))\n",
        "      samples[-1].cat=labels[folder_name[i]]\n",
        "      # display(255-binary_img)\n",
        "train,validation= train_test_split(samples, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "P_PgmgHyP5ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples=[]\n",
        "for sample in validation:\n",
        "  samples.append(sample)\n",
        "for sample in train:\n",
        "  samples.append(sample)\n",
        "for sample in test:\n",
        "  samples.append(sample)"
      ],
      "metadata": {
        "id": "qb7aBm1Hy8QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test By using human imgages(Do not execute this part if it is training phase)https://www.kaggle.com/datasets/sudarshanvaidya/random-images-for-face-emotion-recognition"
      ],
      "metadata": {
        "id": "puDeG8-181ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mask_upper_half(gray_img):\n",
        "    # height, width = gray_img.shape\n",
        "    mask = np.zeros((80, 80), dtype=np.uint8)\n",
        "    mask[:45, :] = 255\n",
        "    masked_img = cv2.bitwise_and(gray_img, mask)\n",
        "    return masked_img\n",
        "\n",
        "def mask_lower_half(gray_img):\n",
        "    # height, width = gray_img.shape\n",
        "    mask = np.zeros((80,80), dtype=np.uint8)\n",
        "    mask[45:, :] = 255\n",
        "    masked_img = cv2.bitwise_and(gray_img, mask)\n",
        "    return masked_img"
      ],
      "metadata": {
        "id": "aWlz8dpKDElN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"face-neutral\"]=2\n",
        "labels[\"emotion\"]=24"
      ],
      "metadata": {
        "id": "n-LFt6rqQfiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load self collected facial data"
      ],
      "metadata": {
        "id": "RYFZCu9JJ4tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples=[]\n",
        "index=0\n",
        "# for k in categories.keys():\n",
        "#   if(\"face\" in categories[k]):\n",
        "#     samples.append(Sample(img=emoji_to_image(k)))\n",
        "#     samples[-1].cat=samples[-1].get_cat(categories[k])\n",
        "#     index+=1\n",
        "import os\n",
        "import cv2\n",
        "folder_name=[\"face-positive\",\"face-negative\",\"face-neutral\"]\n",
        "human_labels={\"face-positive\":0,\"face-negative\":1,\"face-neutral\":2}\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/test_emojis/emoji_kitchen_set'\n",
        "k=1\n",
        "\n",
        "for i in range(len(folder_name)):\n",
        "  file_path = os.path.join(folder_path, folder_name[i])\n",
        "  image_files = [file for file in os.listdir(file_path)]\n",
        "  for file in enumerate(image_files):\n",
        "      fpath = os.path.join(file_path, file[1])\n",
        "      img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1]\n",
        "      img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "      img_gray = cv2.resize(img_gray, (80, 80))\n",
        "      # _, binary_img = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
        "      samples.append(Sample(img=img_gray))\n",
        "      samples[-1].cat=labels[folder_name[i]]\n",
        "      # display(255-binary_img)\n",
        "train,validation= train_test_split(samples, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gQokGvr1cpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load human facial data"
      ],
      "metadata": {
        "id": "lKtHI4StJ0v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "folder_name=[\"face-positive\",\"face-negative\",\"face-neutral\"]\n",
        "human_labels={\"face-positive\":0,\"face-negative\":1,\"face-neutral\":2}\n",
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/Assignment1/LiuYuzhou_A1/human_test'\n",
        "k=1\n",
        "test=[]\n",
        "for i in range(len(folder_name)):\n",
        "  file_path = os.path.join(folder_path, folder_name[i])\n",
        "  image_files = [file for file in os.listdir(file_path)]\n",
        "  for file in enumerate(image_files):\n",
        "      fpath = os.path.join(file_path, file[1])\n",
        "      img = cv2.imread(fpath, cv2.IMREAD_COLOR)[..., ::-1]\n",
        "      img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "      img_gray = cv2.resize(img_gray, (80, 80))\n",
        "      # _, binary_img = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
        "      test.append(Sample(img=img_gray))\n",
        "      test[-1].cat=labels[folder_name[i]]\n",
        "      # display(255-binary_img)"
      ],
      "metadata": {
        "id": "P7cWcxkg80ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mask Strategy\n",
        "If u want to try to use masks stategy, please execute here, it onlt mask the training samples"
      ],
      "metadata": {
        "id": "-RK5lO5ycEzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incoming=[]\n",
        "for sample in train:\n",
        "  new_sample=Sample(img=mask_upper_half(sample.img))\n",
        "  new_sample.cat=sample.cat\n",
        "  incoming.append(new_sample)"
      ],
      "metadata": {
        "id": "XCN4T8v15aIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in train:\n",
        "  new_sample=Sample(img=mask_lower_half(sample.img))\n",
        "  new_sample.cat=sample.cat\n",
        "  incoming.append(new_sample)"
      ],
      "metadata": {
        "id": "ZuT_3evxJTAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in train:\n",
        "  incoming.append(sample)\n",
        "train=incoming"
      ],
      "metadata": {
        "id": "oHqa15ZLKHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples=[]\n",
        "for sample in train:\n",
        "  samples.append(sample)\n",
        "for sample in validation:\n",
        "  samples.append(sample)\n",
        "for sample in test:\n",
        "  samples.append(sample)"
      ],
      "metadata": {
        "id": "9zvzeKYwFacp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "id": "sGvvM9qxKKIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM, Random Forest Classifier,and KNN Classifier"
      ],
      "metadata": {
        "id": "2WcL2--t-1OV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM\n",
        "Just simply train it based on a linear SVM classifier."
      ],
      "metadata": {
        "id": "vtPg3NJIA-Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train an SVM model.\n",
        "train_feats=[np.array(sample.img).flatten() for sample in train]\n",
        "train_cats=[sample.cat for sample in train]\n",
        "val_feats=[np.array(sample.img).flatten() for sample in validation]\n",
        "val_cats=[sample.cat for sample in validation]\n",
        "test_feats=[np.array(sample.img).flatten() for sample in test]\n",
        "test_cats=[sample.cat for sample in test]\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(train_feats, train_cats)\n",
        "\n",
        "# predict on the validation set.\n",
        "y_pred = svm.predict(val_feats)\n",
        "\n",
        "# calculate accuracy.\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "U0XkbhVv-z_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test part"
      ],
      "metadata": {
        "id": "W5RQhMFWcSo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(test_feats)\n",
        "accuracy = accuracy_score(test_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "sRyRcR07cODE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-Fold Validation"
      ],
      "metadata": {
        "id": "qBuWYY7qGljk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X = train_feats\n",
        "y = train_cats\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "k = 10\n",
        "\n",
        "# Perform K-fold cross-validation\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute the mean accuracy\n",
        "accuracy_scores = cross_val_score(svm, X, y, cv=kfold, scoring='accuracy')\n",
        "mean_accuracy = accuracy_scores.mean()\n",
        "# Perform K-fold cross-validation\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute the mean accuracy\n",
        "accuracy_scores = cross_val_score(svm, X, y, cv=kfold, scoring='accuracy')\n",
        "mean_accuracy = accuracy_scores.mean()\n",
        "\n",
        "# Print the accuracy for each fold and the mean accuracy\n",
        "i=1\n",
        "for score in accuracy_scores:\n",
        "  print(\"Accuracy for fold {} : {}\".format(i,score))\n",
        "  i+=1\n",
        "print(mean_accuracy)"
      ],
      "metadata": {
        "id": "aA-KAyFmiPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "oz3I3rBbJZak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train an Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Create an Instance of the Random Forest Classifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
        "\n",
        "# Train the Classifier\n",
        "classifier.fit(train_feats, train_cats)\n",
        "\n",
        "# Step Make Predictions\n",
        "y_pred = classifier.predict(val_feats)\n",
        "\n",
        "# Step Evaluate the Model\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "zA56uVpbAz8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN Classifier"
      ],
      "metadata": {
        "id": "1OG-EjP7J7QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create an Instance of the KNN Classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "\n",
        "# Train the Classifier\n",
        "classifier.fit(train_feats, train_cats)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = classifier.predict(val_feats)\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "5hcIOWncJ3R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Visual world"
      ],
      "metadata": {
        "id": "43lkQ6B3T_DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract sift features for all images in IMHere\n",
        "\n",
        "from scipy.cluster.vq import *\n",
        "from sklearn import preprocessing\n",
        "import cv2\n",
        "\n",
        "imgs = {}\n",
        "des_list = []\n",
        "sift = cv2.SIFT_create()\n",
        "k=0\n",
        "\n",
        "for i in range(len(samples)):\n",
        "    kpt, des = sift.detectAndCompute(samples[i].img, None)\n",
        "    samples[i].sift_des=des\n",
        "    #train by concatenate\n",
        "    kpt1, des1 = sift.detectAndCompute(np.array(samples[i].conv_vert), None)\n",
        "    kpt2,des2 =sift.detectAndCompute(np.array(samples[i].conv_horizon), None)\n",
        "    kpt3,des3 =sift.detectAndCompute(np.array(samples[i].conv_edge), None)\n",
        "    # #train bt max\n",
        "    # max_num_keypoints = 0\n",
        "\n",
        "    # if len(kpt) > max_num_keypoints:\n",
        "    #     max_num_keypoints = len(kpt)\n",
        "    #     samples[i].sift_des=des\n",
        "\n",
        "    # if len(kpt1) > max_num_keypoints:\n",
        "    #     max_num_keypoints = len(kpt1)\n",
        "    #     samples[i].sift_des=des1\n",
        "\n",
        "    # if len(kpt2) > max_num_keypoints:\n",
        "    #     max_num_keypoints = len(kpt2)\n",
        "    #     samples[i].sift_des=des2\n",
        "    # if len(kpt3) > max_num_keypoints:\n",
        "    #     samples[i].sift_des=des3\n",
        "    # Filter out zero-dimensional descriptors\n",
        "    # Create a list to store valid descriptors\n",
        "    #train by combination\n",
        "    descriptors_list = []\n",
        "    if des1 is not None:\n",
        "        descriptors_list.append(des1)\n",
        "    if des2 is not None:\n",
        "        descriptors_list.append(des2)\n",
        "    if des3 is not None:\n",
        "        descriptors_list.append(des3)\n",
        "    if des is not None:\n",
        "        descriptors_list.append(des)\n",
        "    # # Concatenate the descriptors\n",
        "    descriptors = np.concatenate(descriptors_list, axis=0)\n",
        "    samples[i].sift_des=descriptors"
      ],
      "metadata": {
        "id": "XSlnNH-1UZqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[0].sift_des"
      ],
      "metadata": {
        "id": "TWfdsNctf87L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do the clustering\n",
        "# consturct the dictionary\n",
        "from scipy.cluster.vq import vq,kmeans\n",
        "numWords = 1000\n",
        "\n",
        "# TODO: Stack all the descriptors vertically in a numpy array\n",
        "descriptors = samples[0].sift_des\n",
        "for sample in samples[1:]:\n",
        "    descriptors = np.vstack((descriptors,sample.sift_des))\n",
        "\n",
        "# TODO: Perform k-means clustering (using scipy.cluster.vq.kmeans)\n",
        "print(\"Start k-means: %d words, %d key points\" %(numWords, descriptors.shape[0]))\n",
        "voc, variance = kmeans(descriptors,numWords,1)"
      ],
      "metadata": {
        "id": "4zXUDAckXIEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build histograms\n",
        "\n",
        "for i in range(len(samples)):\n",
        "    im_feature = np.zeros((numWords), \"float32\")\n",
        "    # TODO: using scipy.cluster.vq\n",
        "    words, distance = vq(samples[i].sift_des,voc)\n",
        "    for w in words:\n",
        "        im_feature[w] += 1\n",
        "    samples[i].bovw_vec=im_feature\n",
        "# perform L2 normalization\n",
        "# display(np.unique(im_features))\n",
        "# im_features = preprocessing.normalize(im_features, norm='l2')"
      ],
      "metadata": {
        "id": "f37qA69qYQnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "train_feats=[sample.bovw_vec for sample in train]\n",
        "train_cats=[sample.cat for sample in train]\n",
        "val_feats=[sample.bovw_vec for sample in validation]\n",
        "val_cats=[sample.cat for sample in validation]\n",
        "test_feats=[sample.bovw_vec for sample in test]\n",
        "test_cats=[sample.cat for sample in test]\n",
        "svm.fit(train_feats, train_cats)\n",
        "\n",
        "# predict on the validation set.\n",
        "y_pred = svm.predict(val_feats)\n",
        "\n",
        "# calculate accuracy.\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "V-JiRdjjbQpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test part"
      ],
      "metadata": {
        "id": "7t4rD1eggZUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the validation set.\n",
        "y_pred = svm.predict(test_feats)\n",
        "\n",
        "# calculate accuracy.\n",
        "accuracy = accuracy_score(test_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "chgkXbJSe1rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "xtkI-7jNgk1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold validation"
      ],
      "metadata": {
        "id": "1F5m5uShHUf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "X = [sample.bovw_vec for sample in samples]\n",
        "y = [sample.cat for sample in samples]\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "k = 10\n",
        "\n",
        "# Perform K-fold cross-validation\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and compute the mean accuracy\n",
        "accuracy_scores = cross_val_score(svm, X, y, cv=kfold, scoring='accuracy')\n",
        "mean_accuracy = accuracy_scores.mean()\n",
        "\n",
        "# Print the accuracy for each fold and the mean accuracy\n",
        "i=1\n",
        "print(\"Totolly {} images\".format(len(samples)))\n",
        "for score in accuracy_scores:\n",
        "  print(\"SVM(combination) in fold {}'s accuracy : {}%\".format(i,round(score,2)*100))\n",
        "  i+=1\n",
        "print(\"The overall mean score is \"+str(mean_accuracy*100)+\"%\")"
      ],
      "metadata": {
        "id": "q2_Qi2UHVY4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy"
      ],
      "metadata": {
        "id": "UADmz9tyCO_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
        "classifier.fit(train_feats, train_cats)\n",
        "y_pred = classifier.predict(val_feats)\n",
        "\n",
        "# Step Evaluate the Model\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "9letYlhwpH3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of the KNN Classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=2, metric='euclidean')\n",
        "\n",
        "# Train the Classifier\n",
        "classifier.fit(train_feats, train_cats)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = classifier.predict(val_feats)\n",
        "\n",
        "# Step 8: Evaluate the Model\n",
        "accuracy = accuracy_score(val_cats, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "U07TPEhZpc_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train with LBP+CNN\n",
        "\n",
        "1.   We first try to convert all the data points by using LBP method\n",
        "2.   Then we build a CNN to train the model\n",
        "\n"
      ],
      "metadata": {
        "id": "55Skpg_o3wqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# draw the LBP pattern images and feature vectors\n",
        "\n",
        "def unfold(img : np.array, ksize : int = 3) -> np.array:\n",
        "    \"\"\" unfold without center point, only odd kernel size is supported\n",
        "\n",
        "    Params:\n",
        "        img:\n",
        "            An image with size of H x W.\n",
        "        ksize:\n",
        "            The kernel size\n",
        "    \"\"\"\n",
        "    assert ksize % 2 == 1\n",
        "    assert img.ndim == 2\n",
        "    H, W = img.shape\n",
        "    # Expand the orignal image's shape for better moving. For the third channel, we pre-define its dimension as eight,\n",
        "    # the LBP result of each pixel depends on the values ​​of the surrounding 8 points\n",
        "    target = np.zeros((H+ksize-1, W+ksize-1, ksize**2-1), dtype=img.dtype)\n",
        "    n = 0\n",
        "    for h in range(ksize):\n",
        "        for w in range(ksize):\n",
        "            if h == ksize // 2 and w == ksize // 2:\n",
        "                continue\n",
        "            target[h:h+H, w:w+W, n] = img\n",
        "            n += 1\n",
        "    return target[ksize//2:ksize//2+H, ksize//2:ksize//2+W, :]\n",
        "\n",
        "\n",
        "def original_LBP(img : np.array) -> np.array:\n",
        "    \"\"\" calculate the original version of LBP\n",
        "\n",
        "    Params:\n",
        "        img:\n",
        "            An image with size of H x W.\n",
        "\n",
        "    Pattern:\n",
        "        4 3 2\n",
        "        5 / 1\n",
        "        6 7 8\n",
        "    \"\"\"\n",
        "    img_unfold = unfold(img)\n",
        "    factor1 = img_unfold >= img[..., None]\n",
        "    factor2 = np.array([128, 64, 32, 1, 16, 2, 4, 8], dtype=np.int32)\n",
        "    return np.sum((factor1 * factor2), axis=-1)\n",
        "for s in samples:\n",
        "  s.lbp_feat=original_LBP(s.img)"
      ],
      "metadata": {
        "id": "OVTPS_mQlrl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_gray_image(image):\n",
        "    # Convert the image to float32 data type\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    # Apply normalization\n",
        "    normalized_image = (image - np.mean(image)) / np.std(image)\n",
        "\n",
        "    return normalized_image"
      ],
      "metadata": {
        "id": "3juc5heOiFMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split feature and label of the train set and validation set"
      ],
      "metadata": {
        "id": "OcoxqbObC6J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_feats=[normalize_gray_image(sample.img) for sample in train]\n",
        "train_cats=[sample.cat for sample in train]\n",
        "val_feats=[normalize_gray_image(sample.img) for sample in validation]\n",
        "val_cats=[sample.cat for sample in validation]\n",
        "test_feats=[normalize_gray_image(sample.img) for sample in test]\n",
        "test_cats=[sample.cat for sample in test]"
      ],
      "metadata": {
        "id": "yd6dLxJzcF1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cats"
      ],
      "metadata": {
        "id": "CuxQwuLKVGyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use one hot encoding in order to use the softmax for prediction in CNN"
      ],
      "metadata": {
        "id": "8haq661NYjGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adjust it according to the number of categories of current class\n",
        "num_cats=25"
      ],
      "metadata": {
        "id": "3-qtmrxjhAMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_cats = [[0] * num_cats for _ in range(len(train_cats))]\n",
        "for i in range(len(train_cats)):\n",
        "  temp_cats[i][train_cats[i]]=1\n",
        "train_cats=temp_cats\n",
        "temp_cats = [[0] * num_cats for _ in range(len(val_cats))]\n",
        "for i in range(len(val_cats)):\n",
        "  temp_cats[i][val_cats[i]]=1\n",
        "val_cats=temp_cats\n",
        "temp_cats = [[0] * num_cats for _ in range(len(test_cats))]\n",
        "for i in range(len(test_cats)):\n",
        "  temp_cats[i][test_cats[i]]=1\n",
        "test_cats=temp_cats"
      ],
      "metadata": {
        "id": "zwxJdEbwQB9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is the EMONN model"
      ],
      "metadata": {
        "id": "Eo7LUb9wHrcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import Tensor\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "x_train = torch.tensor(train_feats).to(torch.float32)\n",
        "x_train = torch.reshape(x_train,[x_train.shape[0],1,80,80])\n",
        "y_train=torch.tensor(train_cats).to(torch.float32)\n",
        "# x_test = torch.tensor(test_samples).to(torch.float32)\n",
        "x_val = torch.tensor(val_feats).to(torch.float32)\n",
        "y_val = torch.tensor(val_cats).to(torch.float32)\n",
        "x_test = torch.tensor(test_feats).to(torch.float32)\n",
        "y_test = torch.tensor(test_cats).to(torch.float32)\n",
        "# Specify batch size\n",
        "batch_size = 32\n",
        "num_batches = len(x_train) // batch_size\n",
        "num_epochs=50\n",
        "output_channel=num_cats\n",
        "class EMONN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EMONN, self).__init__()\n",
        "        #because the shape of the image is gray image, so the input chaneel should be 1\n",
        "        self.conv1 = nn.Conv2d(1,6,kernel_size=5)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6,16, kernel_size=5)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.linear1 = nn.Linear(16*17*17, 80)\n",
        "        self.linear2 = nn.Linear(80,output_channel)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    # forward function is inherted from parent's class. x denotes the input feature.\n",
        "    def forward(self, x):\n",
        "        y_pred = self.conv1(x)\n",
        "        y_pred = F.relu(y_pred)\n",
        "        train_conv=y_pred\n",
        "        y_pred = self.pool1(y_pred)\n",
        "        y_pred = F.relu(self.conv2(y_pred))\n",
        "        y_pred = self.pool2(y_pred)\n",
        "        y_pred = y_pred.view(-1,16*17*17)\n",
        "        y_pred = F.relu(self.linear1(y_pred))\n",
        "        y_pred = self.linear2(y_pred)\n",
        "        return y_pred,train_conv\n",
        "\n",
        "# create model\n",
        "model = EMONN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# create optimizer. 1st parameter: the parameters will be optimized; 2nd: learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "train_conv=[]\n",
        "# Define the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = (batch_idx + 1) * batch_size\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = Variable(x_train[start_idx:end_idx]).cuda()\n",
        "            target = Variable(y_train[start_idx:end_idx]).cuda()\n",
        "        else:\n",
        "            inputs = Variable(x_train[start_idx:end_idx])\n",
        "            target = Variable(y_train[start_idx:end_idx])\n",
        "                # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        out,_= model(inputs)\n",
        "        # Calculate loss\n",
        "        loss = criterion(out, target)\n",
        "\n",
        "        # Backward propagation\n",
        "        loss.backward()\n",
        "        # Updating parameters via SGD\n",
        "        optimizer.step()\n",
        "        # Print training progress\n",
        "        if(batch_idx==num_batches-1):\n",
        "          print(f\"Batch {batch_idx+1}/{num_batches} - Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "-_mSyPsvTwvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the midle generate images"
      ],
      "metadata": {
        "id": "DTr1Y20GHyHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_feats=[normalize_gray_image(sample.img) for sample in train]\n",
        "train_cats=[sample.cat for sample in train]\n",
        "val_feats=[normalize_gray_image(sample.img) for sample in validation]\n",
        "val_cats=[sample.cat for sample in validation]\n",
        "test_feats=[normalize_gray_image(sample.img) for sample in test]\n",
        "test_cats=[sample.cat for sample in test]"
      ],
      "metadata": {
        "id": "-szU-9_UmWuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_conv=model(x_train)\n",
        "result1,val_conv=model(torch.reshape(x_val,[x_val.shape[0],1,80,80]))\n",
        "test_result,test_conv=model(torch.reshape(x_test,[x_test.shape[0],1,80,80]))"
      ],
      "metadata": {
        "id": "9P4uudh-Wdbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation part"
      ],
      "metadata": {
        "id": "TFxg4WpBH9Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum value for each 1D element\n",
        "result1=np.array(torch.detach(result1))\n",
        "max_values = max_indices = np.argmax(result1, axis=1)\n",
        "\n",
        "# Print the maximum values\n"
      ],
      "metadata": {
        "id": "YjaVjUd9m_T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(val_cats, max_values)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "paf_E9inrQal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test part"
      ],
      "metadata": {
        "id": "Qy10PKA-H627"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the maximum value for each 1D element\n",
        "result=np.array(torch.detach(test_result))\n",
        "max_values = max_indices = np.argmax(result, axis=1)\n",
        "\n",
        "# Print the maximum values\n",
        "accuracy = accuracy_score(test_cats, max_values)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "ixTkHYbvibdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_values"
      ],
      "metadata": {
        "id": "PiNPrBMUAReL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Midway method"
      ],
      "metadata": {
        "id": "UfFREFn6t7Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_conv=np.array(torch.detach(train_conv))\n",
        "val_conv=np.array(torch.detach(val_conv))\n",
        "test_conv=np.array(torch.detach(test_conv))"
      ],
      "metadata": {
        "id": "-pLmDOlQev0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_edge(Image.fromarray(train[0].img))"
      ],
      "metadata": {
        "id": "k_LWcf3r2ZKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample,imgs in zip(train,train_conv):\n",
        "  sample.conv= imgs\n",
        "for sample,imgs in zip(validation,val_conv):\n",
        "  sample.conv=imgs\n",
        "for sample,imgs in zip(test,test_conv):\n",
        "  sample.conv=imgs"
      ],
      "metadata": {
        "id": "sDGuU56e0Gqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[0].conv[1].shape"
      ],
      "metadata": {
        "id": "E-qxC0MGTgDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(5, 6, figsize=(20, 20))  # Adjust the figsize as needed\n",
        "for j in range(5):\n",
        "  for i in range(train[0].conv.shape[0]):\n",
        "      axs[j,i].imshow(cv2.convertScaleAbs(samples[j].conv[i], alpha=(255.0)), cmap='gray')\n",
        "      axs[j,i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QsiXdXvp6fxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract sift features for all images in IMHere\n",
        "\n",
        "from scipy.cluster.vq import *\n",
        "from sklearn import preprocessing\n",
        "import cv2\n",
        "\n",
        "imgs = {}\n",
        "des_list = []\n",
        "sift = cv2.SIFT_create()\n",
        "k=0\n",
        "\n",
        "for j in range(len(samples)):\n",
        "    descriptor_list=[]\n",
        "    i=0\n",
        "    samples[j].sift_des=[]\n",
        "    for i in range(samples[j].conv.shape[0]):\n",
        "      new_img=cv2.convertScaleAbs(samples[j].conv[i], alpha=(255.0))\n",
        "      kpt, des = sift.detectAndCompute(new_img, None)\n",
        "      if(des is not None):\n",
        "        samples[j].sift_des.append(des)\n",
        "      # print(len(kpt))\n",
        "      # display(cv2.convertScaleAbs(samples[j].conv[i], alpha=(255.0)))\n",
        "\n",
        "      # if(des is not None):\n",
        "      #   descriptor_list.append(des)\n",
        "      # kpt, des = sift.detectAndCompute(cv2.convertScaleAbs(samples[j].conv[i], alpha=(255.0)), None)\n",
        "\n",
        "    # if(len(descriptor_list)!=6):\n",
        "    #   print(len(descriptor_list))\n",
        "    # descriptors = np.concatenate(descriptors_list, axis=0)\n",
        "    # samples[i].sift_des=descriptors\n",
        "    # k+=descriptors.shape[0]"
      ],
      "metadata": {
        "id": "6bbVQ7Ejb8Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do the clustering\n",
        "# consturct the dictionary\n",
        "from scipy.cluster.vq import vq,kmeans\n",
        "numWords = 125\n",
        "all_pred=[]\n",
        "all_test_pred=[]\n",
        "classifier = RandomForestClassifier()\n",
        "for ind in range(5):\n",
        "  # TODO: Stack all the descriptors vertically in a numpy array\n",
        "  descriptors = samples[0].sift_des[ind]\n",
        "  for sample in samples[1:]:\n",
        "    descriptors = np.vstack((descriptors,sample.sift_des[ind]))\n",
        "  # TODO: Perform k-means clustering (using scipy.cluster.vq.kmeans)\n",
        "  print(\"Start k-means: %d words, %d key points\" %(numWords, descriptors.shape[0]))\n",
        "  voc, variance = kmeans(descriptors,numWords,1)\n",
        "  for s in range(len(train)):\n",
        "    im_feature = np.zeros((numWords), \"float32\")\n",
        "    # TODO: using scipy.cluster.vq\n",
        "    words, distance = vq(train[s].sift_des[ind],voc)\n",
        "    for w in words:\n",
        "        im_feature[w] += 1\n",
        "    train[s].bovw_vec=im_feature\n",
        "  for s in range(len(validation)):\n",
        "      im_feature = np.zeros((numWords), \"float32\")\n",
        "      # TODO: using scipy.cluster.vq\n",
        "      words, distance = vq(validation[s].sift_des[ind],voc)\n",
        "      for w in words:\n",
        "          im_feature[w] += 1\n",
        "      validation[s].bovw_vec=im_feature\n",
        "  '''\n",
        "  Enable only when testing\n",
        "  '''\n",
        "  for s in range(len(test)):\n",
        "      im_feature = np.zeros((numWords), \"float32\")\n",
        "      # TODO: using scipy.cluster.vq\n",
        "      words, distance = vq(test[s].sift_des[ind],voc)\n",
        "      for w in words:\n",
        "          im_feature[w] += 1\n",
        "      test[s].bovw_vec=im_feature\n",
        "  test_feats=[sample.bovw_vec for sample in test]\n",
        "  test_cats=[sample.cat for sample in test]\n",
        "\n",
        "  train_feats=[sample.bovw_vec for sample in train]\n",
        "  train_cats=[sample.cat for sample in train]\n",
        "  val_feats=[sample.bovw_vec for sample in validation]\n",
        "  val_cats=[sample.cat for sample in validation]\n",
        "  classifier = RandomForestClassifier()\n",
        "  classifier.fit(train_feats, train_cats)\n",
        "  # predict on the validation set.\n",
        "  y_pred = classifier.predict(val_feats)\n",
        "  all_pred.append(y_pred)\n",
        "  accuracy = accuracy_score(val_cats, y_pred)\n",
        "  print(f'Val Accuracy: {accuracy * 100:.2f}%')\n",
        "  ######################################\n",
        "  test_pred=classifier.predict(test_feats)\n",
        "  all_test_pred.append(test_pred)\n",
        "  # train_pred=svm.predict(train_feats)\n",
        "  # calculate accuracy.\n",
        "  accuracy = accuracy_score(test_cats, test_pred)\n",
        "  print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "cNBiYfWmpqs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram extraction"
      ],
      "metadata": {
        "id": "bOW8x-gx4CSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "for j in range(len(samples)):\n",
        "  for i in range(samples[j].conv.shape[0]):\n",
        "      # axs[j,i].imshow(cv2.convertScaleAbs(samples[j].conv[i], alpha=(255.0)), cmap='gray')\n",
        "      # axs[j,i].axis('off')\n",
        "    column_histograms = []\n",
        "    for row in range(samples[j].conv[i].shape[0]):\n",
        "      sum=0\n",
        "      for column in range(samples[j].conv[i].shape[1]):\n",
        "        sum+=samples[j].conv[i][row][column]\n",
        "      column_histograms.append(sum)\n",
        "    samples[j].histogram.append(column_histograms)"
      ],
      "metadata": {
        "id": "fdqXPN_9lXef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "all_pred=[]\n",
        "all_test_pred=[]\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "for i in range(6):\n",
        "  svm = RandomForestClassifier()\n",
        "  train_feats=[sample.histogram[i] for sample in train]\n",
        "  train_cats=[sample.cat for sample in train]\n",
        "  val_feats=[sample.histogram[i] for sample in validation]\n",
        "  val_cats=[sample.cat for sample in validation]\n",
        "  svm.fit(train_feats, train_cats)\n",
        "\n",
        "  # predict on the validation set.\n",
        "  y_pred = svm.predict(val_feats)\n",
        "  all_pred.append(y_pred)\n",
        "\n",
        "  # calculate accuracy.\n",
        "  accuracy = accuracy_score(val_cats, y_pred)\n",
        "  print(f'Random Forest: Accuracy for sub-group {i+1}: {accuracy * 100:.2f}%')\n",
        "  test_feats=[sample.histogram[i] for sample in test]\n",
        "  test_cats=[sample.cat for sample in test]\n",
        "  y_pred = svm.predict(test_feats)\n",
        "  all_test_pred.append(y_pred)\n",
        "  accuracy = accuracy_score(test_cats, y_pred)\n",
        "  print(f'Random Forest: Accuracy for test-group {i+1}: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "aganTyGgH6Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a Voting strategy"
      ],
      "metadata": {
        "id": "VLio9y2qOOhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_pred"
      ],
      "metadata": {
        "id": "WoemwMiO3imf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation vote\n"
      ],
      "metadata": {
        "id": "8u8wFvKQOWog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vote=[]\n",
        "for i in range(len(all_pred[0])):\n",
        "  pred_for_each=[]\n",
        "  for j in range(len(all_pred)):\n",
        "    pred_for_each.append(all_pred[j][i])\n",
        "  vote.append(pred_for_each)"
      ],
      "metadata": {
        "id": "cv7xdBLx9sym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(vote).shape"
      ],
      "metadata": {
        "id": "HtJSj_w-Lkq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_for_each"
      ],
      "metadata": {
        "id": "Vs3M_-_LMGST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "vote_result=[]\n",
        "for i in range(len(vote)):\n",
        "  # Define the training results\n",
        "  training_results = np.array(vote[i])\n",
        "\n",
        "  # Perform voting\n",
        "  result = np.argmax(np.bincount(training_results))\n",
        "  vote_result.append(result)"
      ],
      "metadata": {
        "id": "UFQJt-qJKlz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(vote_result, val_cats)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "gcmTAclBNqrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "CLgFtwZ6jCGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test vote"
      ],
      "metadata": {
        "id": "Z-gcq4d9IjdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_vote=[]\n",
        "for i in range(len(all_test_pred[0])):\n",
        "  pred_for_each=[]\n",
        "  for j in range(len(all_test_pred)):\n",
        "    pred_for_each.append(all_test_pred[j][i])\n",
        "  test_vote.append(pred_for_each)"
      ],
      "metadata": {
        "id": "QUeFeHd6nqgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "vote_result=[]\n",
        "for i in range(len(test_vote)):\n",
        "  # Define the training results\n",
        "  training_results = np.array(test_vote[i])\n",
        "\n",
        "  # Perform voting\n",
        "  result = np.argmax(np.bincount(training_results))\n",
        "  vote_result.append(result)"
      ],
      "metadata": {
        "id": "c7-GwoyB-Ox-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = accuracy_score(vote_result, test_cats)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "kWkaIe3B9yDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of test and validation result"
      ],
      "metadata": {
        "id": "2T6bPulTIVlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Create a figure and subplots\n",
        "fig, axes = plt.subplots(2, 4, figsize=(10, 6))\n",
        "k=0\n",
        "switched_dict = {value: key for key, value in labels.items()}\n",
        "# Plot each image in the corresponding subplot\n",
        "print(\"Validate vote accuracy is {}%\".format(accuracy*100))\n",
        "print(\"Test vote accuracy is {}%\".format(test_accuracy*100))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(test[i].img)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(switched_dict[vote_result[k]])\n",
        "    k+=1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lxECIZnE9JE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "math",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}